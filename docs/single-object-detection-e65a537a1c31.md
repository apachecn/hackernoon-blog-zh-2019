# æ£€æµ‹å›¾åƒä¸­æœ€å¤§ç‰©ä½“çš„ ML æ¨¡å‹â€”â€”ç¬¬ 1 éƒ¨åˆ†

> åŸæ–‡ï¼š<https://medium.com/hackernoon/single-object-detection-e65a537a1c31>

## 1 -å›´ç»•å›¾åƒä¸­æœ€å¤§çš„å¯¹è±¡ç»˜åˆ¶è¾¹ç•Œæ¡†ã€‚è¿™æ˜¯ä¸ºäº†å‡†å¤‡å¥½å›¾åƒæ•°æ®è¿›è¡Œåˆ†æã€‚

![](img/eac0d69fa13c606cb48512dcc9ae954c.png)

æ¬¢è¿æ¥åˆ° fast.ai çš„ç¬¬ 2 éƒ¨åˆ†ï¼Œåœ¨è¿™é‡Œæˆ‘ä»¬å°†å¤„ç†**å•ä¸ªç‰©ä½“æ£€æµ‹ã€‚**åœ¨æˆ‘ä»¬å¼€å§‹ä¹‹å‰ï¼Œæˆ‘è¦æ„Ÿè°¢[](https://twitter.com/jeremyphoward)**å’Œ [**ç‘ç§‹Â·æ‰˜é©¬æ–¯**](https://twitter.com/math_rachel) ä¸º AI æ°‘ä¸»åŒ–æ‰€åšçš„åŠªåŠ›ã€‚**

**æœ¬éƒ¨åˆ†å‡è®¾æ‚¨å·²ç»å¾ˆå¥½åœ°ç†è§£äº†ç¬¬ 1 éƒ¨åˆ†ã€‚ä»¥ä¸‹æ˜¯é“¾æ¥ï¼Œè¯·æŒ‰ä»¥ä¸‹é¡ºåºéšæ„æ¢ç´¢æœ¬ç³»åˆ—çš„ç¬¬ä¸€éƒ¨åˆ†ã€‚**

1.  **[ç‹— Vs çŒ«å›¾åƒåˆ†ç±»](https://towardsdatascience.com/fast-ai-season-1-episode-2-1-e9cc80d81a9d)**
2.  **[çŠ¬ç§å›¾åƒåˆ†ç±»](https://towardsdatascience.com/fast-ai-season-1-episode-2-2-dog-breed-classification-5555c0337d60)**
3.  **[å¤šæ ‡ç­¾å›¾åƒåˆ†ç±»](https://towardsdatascience.com/fast-ai-season-1-episode-3-a-case-of-multi-label-classification-a4a90672a889)**
4.  **[ä½¿ç”¨ç¥ç»ç½‘ç»œçš„æ—¶é—´åºåˆ—åˆ†æ](https://towardsdatascience.com/fast-ai-season-1-episode-4-1-time-series-analysis-a23217418bf1)**
5.  **[å¯¹ IMDB ç”µå½±æ•°æ®é›†çš„ NLP æƒ…æ„Ÿåˆ†æ](https://geneashis.medium.com/nlp-sentiment-analysis-on-imdb-movie-dataset-fb0c4d346d23)**
6.  **[ç”µå½±æ¨èç³»ç»ŸåŸºç¡€](https://towardsdatascience.com/fast-ai-season-1-episode-5-1-movie-recommendation-using-fastai-a53ed8e41269)**
7.  **[ä»é›¶å¼€å§‹ååŒè¿‡æ»¤](https://towardsdatascience.com/fast-ai-season-1-episode-5-2-collaborative-filtering-from-scratch-1877640f514a)**
8.  **[ä½¿ç”¨ç¥ç»ç½‘ç»œçš„ååŒè¿‡æ»¤](https://towardsdatascience.com/fast-ai-season-1-episode-5-3-collaborative-filtering-using-neural-network-48e49d7f9b36)**
9.  **[åƒå°¼é‡‡ä¸€æ ·å†™å“²å­¦](https://geneashis.medium.com/fast-ai-season-1-episode-6-1-write-philosophy-like-nietzsche-using-rnn-8fe70cfb923c)**
10.  **[ä¸åŒç¥ç»ç½‘ç»œåœ¨ Cifar-10 æ•°æ®é›†ä¸Šçš„æ€§èƒ½](https://geneashis.medium.com/fast-ai-season-1-episode-7-1-performance-of-different-neural-networks-on-cifar-10-dataset-c6559595b529)**
11.  **[ML æ¨¡å‹æ£€æµ‹å›¾åƒä¸­æœ€å¤§çš„ç‰©ä½“ Part-1](/hackernoon/single-object-detection-e65a537a1c31)**
12.  **[æ£€æµ‹å›¾åƒä¸­æœ€å¤§ç‰©ä½“çš„ ML æ¨¡å‹ Part-2](/hackernoon/single-object-detection-part-2-2deafc911ce7)**

**è¿™ç¯‡åšæ–‡åˆ†ä¸ºä¸¤éƒ¨åˆ†ã€‚**

*   **ç¬¬ä¸€éƒ¨åˆ†ä»ç†Ÿæ‚‰å¯¹è±¡æ£€æµ‹åˆ°å¯¹è±¡å®šä½çš„æ•°æ®æ ¼å¼å¼€å§‹ã€‚**
*   **ç¬¬äºŒéƒ¨åˆ†å¤„ç†å›¾åƒä¸­çš„æœ€å¤§é¡¹ç›®åˆ†ç±»å™¨ã€‚**

**æˆ‘ä»¬å°†ä½¿ç”¨çš„æ•°æ®é›†æ˜¯ PASCAL VOC (2007 ç‰ˆ)ã€‚**

**è®©æˆ‘ä»¬ç”¨ç¼–ç éƒ¨åˆ†æ¥å¼„è„æˆ‘ä»¬çš„æ‰‹ã€‚**

**ä¸æ‰€æœ‰æœºå™¨å­¦ä¹ é¡¹ç›®ä¸€æ ·ï¼Œæœ‰ä¸‰ä»¶äº‹éœ€è¦å…³æ³¨**

1.  ***æä¾›æ•°æ®ã€‚***
2.  ***æŒ‘é€‰ä¸€äº›åˆé€‚çš„æ¶æ„ã€‚***
3.  ***é€‰æ‹©ä¸€ä¸ªæŸå¤±å‡½æ•°ã€‚***

****ç¬¬ 1 æ­¥**å°†é›†ä¸­äºä»¥é€‚å½“çš„å½¢å¼è·å¾—æ•°æ®ï¼Œä»¥ä¾¿åœ¨æ­¤åŸºç¡€ä¸Šè¿›è¡Œåˆ†æã€‚**

****æ­¥éª¤ 1:-** å®ƒåŒ…æ‹¬å¯¹æ¯å¹…å›¾åƒä¸­æœ€å¤§çš„ç‰©ä½“è¿›è¡Œåˆ†ç±»å’Œå®šä½ã€‚è¯¥æ­¥éª¤åŒ…æ‹¬:-**

*   **å¯¹å¯¹è±¡è¿›è¡Œåˆ†ç±»ã€‚**
*   **å®šä½ç‰©ä½“ã€‚**
*   **æ ‡è®°å®šä½çš„å¯¹è±¡ã€‚**
*   **ç„¶åæˆ‘ä»¬ä¼šå°è¯•ä¸€æ¬¡å®Œæˆä»¥ä¸Šä¸‰ä¸ªæ­¥éª¤ã€‚**

*****1.1ã€‚å®‰è£…è½¯ä»¶åŒ…*å’Œ****

**è®©æˆ‘ä»¬ä½¿ç”¨å¦‚ä¸‹æ‰€ç¤ºçš„å‘½ä»¤å®‰è£…è½¯ä»¶åŒ…å¹¶ä¸‹è½½æ•°æ®ã€‚**

```
# Install the packages
# !pip install [https://github.com/fastai/fastai/archive/master.zip](https://github.com/fastai/fastai/archive/master.zip)
!pip install fastai==0.7.0
!pip install torchtext==0.2.3
!pip install opencv-python
!apt update && apt install -y libsm6 libxext6
!pip3 install [http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl](http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl) 
!pip3 install torchvision# Download the Data to the required folder
!mkdir data
!wget [http://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar](http://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar) -P data/
!wget [https://storage.googleapis.com/coco-dataset/external/PASCAL_VOC.zip](https://storage.googleapis.com/coco-dataset/external/PASCAL_VOC.zip) -P data/
!tar -xf data/VOCtrainval_06-Nov-2007.tar -C data/
!unzip data/PASCAL_VOC.zip -d data/
!rm -rf data/PASCAL_VOC.zip data/VOCtrainval_06-Nov-2007.tar%matplotlib inline
%reload_ext autoreload
%autoreload 2!pip install Pillowfrom fastai.conv_learner import *
from fastai.dataset import *from pathlib import Path
import json
import PIL
from matplotlib import patches, patheffects 
```

**è®©æˆ‘ä»¬æ£€æŸ¥ä¸€ä¸‹æˆ‘ä»¬çš„æ•°æ®ä¸­æœ‰ä»€ä¹ˆã€‚æˆ‘ä»¬å°†ä½¿ç”¨ python 3 æ ‡å‡†åº“`pathlib`è¿›è¡Œè·¯å¾„å’Œæ–‡ä»¶è®¿é—®ã€‚**

*****1.2ã€‚ä½¿ç”¨*** `***Pathlib***` ***å¯¹è±¡äº†è§£ä½ çš„æ•°æ®ã€‚*****

**`data`æ–‡ä»¶å¤¹åŒ…å«ä¸åŒç‰ˆæœ¬çš„ [Pascal VOC](http://host.robots.ox.ac.uk/pascal/VOC/voc2007/) ã€‚**

```
PATH = Path('data')
list((PATH/'PASCAL_VOC').iterdir())
**# iterdir() helps in iterating through the directory of PASCAL_VOC**
```

**![](img/c2b23bacb67d000da889bf50e5e7e760.png)**

*   **`PATH`æ˜¯å¯¹ç›®å½•æˆ–æ–‡ä»¶çš„é¢å‘å¯¹è±¡çš„è®¿é—®ã€‚å®ƒæ˜¯ python åº“`pathlib`çš„ä¸€éƒ¨åˆ†ã€‚è¦äº†è§£å¦‚ä½•åˆ©ç”¨`pathlib` åŠŸèƒ½ï¼Œè¯·åšä¸€ä¸ª`PATH.TAB`ã€‚**
*   **å› ä¸ºæˆ‘ä»¬å°†åªä½¿ç”¨`pascal_train2007.json`ï¼Œæ‰€ä»¥è®©æˆ‘ä»¬æ¥çœ‹çœ‹è¿™ä¸ªæ–‡ä»¶çš„å†…å®¹ã€‚**

```
training_json = json.load((PATH/'PASCAL_VOC''pascal_train2007.json').open())
**# training_json is a dictionary variable.
# As we can see Pathlib object has an open method .
# json.load is a part of Json (Java Script Object Notation) library that # we have imported earlier.**training_json.keys()
```

**![](img/a309edfb07f3aa277289977891b46ccb.png)**

**è¯¥æ–‡ä»¶åŒ…å«**å›¾åƒã€ç±»å‹ã€æ³¨é‡Šå’Œç±»åˆ«**ã€‚ä¸ºäº†ä½¿ç”¨*åˆ¶è¡¨å®Œæˆ*ï¼Œå°†å…¶ä¿å­˜åœ¨é€‚å½“çš„å˜é‡åä¸­ã€‚**

```
IMAGES,ANNOTATIONS,CATEGORIES = ['images', 'annotations', 'categories']
```

**è®©æˆ‘ä»¬è¯¦ç»†çœ‹çœ‹æ¯ä¸€ä¸ªéƒ½æœ‰å“ªäº›ç»†èŠ‚:-**

**![](img/839b4a6b066132984a59147a89e1c568.png)**

*   ****å›¾åƒ**ç”±**å›¾åƒåç§°ã€é«˜åº¦ã€å®½åº¦å’Œå›¾åƒ id** ç»„æˆã€‚**

**![](img/3970e866f710c7964f74100d6f4fab4f.png)**

*   ****æ³¨é‡Š**ç”±**åŒºåŸŸã€bbox(è¾¹ç•Œæ¡†)ã€category_id** ç»„æˆ(æ¯ä¸ªç±»åˆ« id éƒ½æœ‰ä¸€ä¸ªä¸ä¹‹ç›¸å…³çš„ç±»æˆ–åç§°)ã€‚**
*   **ä¸€äº›å›¾åƒå…·æœ‰å¤šè¾¹å½¢åˆ†å‰²ï¼Œå³å›¾åƒä¸­å¯¹è±¡å‘¨å›´çš„è¾¹ç•Œæ¡†ã€‚è¿™å¯¹æˆ‘ä»¬çš„è®¨è®ºä¸é‡è¦ã€‚**
*   **å¦‚æœ**å¿½ç•¥æ ‡å¿—=1(çœŸ)ï¼Œå¿½ç•¥æ ‡å¿—è¡¨ç¤ºå¿½ç•¥å›¾åƒä¸­çš„å¯¹è±¡ã€‚****

**![](img/db48ebb416112a47689266487ecfd1ce.png)**

*   ****ç±»åˆ«**ç”±ç±»(åç§°)å’Œä¸ä¹‹ç›¸å…³çš„ ID ç»„æˆã€‚**

**ä¸ºäº†æ›´å®¹æ˜“ç†è§£æ‰€æœ‰è¿™äº›ï¼Œè®©æˆ‘ä»¬æŠŠé‡è¦çš„ä¸œè¥¿è½¬æ¢æˆå­—å…¸ç†è§£å’Œåˆ—è¡¨ç†è§£ã€‚**

```
FILE_NAME,ID,IMG_ID,CATEGORY_ID,BBOX = 'file_name','id','image_id','category_id','bbox'categories = {o[ID]:o['name'] for o in training_json[CATEGORIES]}
**# The categories is a dictionary having  class and an ID associated with # it.**
**# Lets check out all of the 20 categories using the command below**
categories
```

**![](img/7930f2caf9402eabcfa57de91498bf6a.png)**

```
**training_filenames = {o[ID]:o[FILE_NAME] for o in training_json[IMAGES]}
training_filenames** 
# contains the id and the filename of the images.
```

**![](img/99b9a7af9c191fc37779ca1e87016c8a.png)**

```
**training_ids = [o[ID] for o in training_json[IMAGES]]
training_ids** # This is a list comprehension.
```

**![](img/0f1e5d40fd4773c77f8ec25a84703aa2.png)**

**ç°åœ¨ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹å­˜æ”¾æ‰€æœ‰å›¾åƒçš„æ–‡ä»¶å¤¹ã€‚**

```
list((PATH/'VOCdevkit'/'VOC2007').iterdir())
**# The JPEGImages in red is the one with all the Images in it.**
```

**![](img/8a5bb555318bd3c9b43078d932c9050b.png)**

```
JPEGS = 'VOCdevkit/VOC2007/JPEGImages'
IMG_PATH = PATH/JPEGS
**# Set the path of the Images as IMG_PATH** list(IMG_PATH.iterdir())[:5]
**# Check out all the Images in the Path**
```

**![](img/586a3982d68127370cbf13df6a5845eb.png)****![](img/9b79cb5956a535d4c3d342de8267ab25.png)****![](img/44c5636c552a6aa4ebd8bb8b95584dd7.png)**

****æ³¨æ„:-å¦‚ä¸Šæ‰€ç¤ºï¼Œæ¯ä¸ªå›¾åƒéƒ½æœ‰ä¸€ä¸ªä¸ä¹‹ç›¸å…³è”çš„å”¯ä¸€ idã€‚****

*****1.3ã€‚è¾¹ç•Œæ¡†*****

**è¿™é‡Œçš„ä¸»è¦ç›®çš„æ˜¯å°†æˆ‘ä»¬çš„è¾¹ç•Œæ¡†è½¬æ¢æˆåˆé€‚çš„æ ¼å¼ï¼Œä»¥ä¾¿ç”¨äºç»˜å›¾ã€‚è¾¹ç•Œæ¡†åæ ‡å‡ºç°åœ¨æ³¨é‡Šä¸­ã€‚**

> **è¾¹ç•Œæ¡†æ˜¯å›¾åƒä¸­å¯¹è±¡å‘¨å›´çš„æ¡†ã€‚**

**æ—©å…ˆè¾¹ç•Œæ¡†åæ ‡è¡¨ç¤º(åˆ—ï¼Œè¡Œï¼Œé«˜åº¦ï¼Œå®½åº¦)ã€‚çœ‹çœ‹ä¸‹é¢çš„å›¾ç‰‡ã€‚**

**![](img/7a4645a9dcd1d7fdf930624b85753ab5.png)**

*   **é€šè¿‡ **hw_bb()** å‡½æ•°å°†åæ ‡è½¬æ¢ä¸º height_width åˆ° bounding_boxï¼Œå¾—åˆ°å·¦ä¸Šè§’å’Œå³ä¸‹è§’çš„åæ ‡ï¼Œå¹¶ä»¥(è¡Œå’Œåˆ—)çš„å½¢å¼è¡¨ç¤ºã€‚**

```
**def hw_bb(bb): return np.array([bb[1], bb[0], bb[3]+bb[1]-1, bb[2]+bb[0]-1])**
```

*   **ç°åœ¨ï¼Œæˆ‘ä»¬å°†**åˆ›å»ºä¸€ä¸ªå­—å…¸ï¼Œè¯¥å­—å…¸å°†å›¾åƒ id ä½œä¸º*é”®*ï¼Œå…¶è¾¹ç•Œæ¡†åæ ‡å’Œç±»åˆ« id ä½œä¸º*å€¼*** ã€‚**

```
**# Python's defaultdict is useful any time you want to have a default     # dictionary entry for new keys. If you try and access a key that doesnâ€™t # exist, it magically makes itself exist and 
# it sets itself equal to the return value of the function you specify   # (in this case lambda:[]).**
training_annotations = collections.defaultdict(lambda:[])
for o in training_json[ANNOTATIONS]:
    if not o['ignore']:
        bb = o[BBOX]
        bb = hw_bb(bb)
        training_annotations[o[IMG_ID]].append((bb,o[CATEGORY_ID]))
```

**![](img/af7eb1987f6039a837aeb57ebc3f29eb.png)**

*   **åœ¨ä¸Šé¢çš„ä»£ç å—ä¸­ï¼Œæˆ‘ä»¬æ£€æŸ¥äº†æ‰€æœ‰çš„æ³¨é‡Šï¼Œå¹¶è€ƒè™‘äº†é‚£äº›æ²¡æœ‰è¯´ ignore çš„æ³¨é‡Šã€‚ä¹‹åï¼Œæˆ‘ä»¬å°†å®ƒæ·»åŠ åˆ°ä¸€ä¸ª**å­—å…¸ä¸­ï¼Œå­—å…¸ä¸­çš„å€¼æ˜¯è¾¹ç•Œæ¡†(bbox)å’Œç±»åˆ« id(class ),å¯¹åº”çš„å›¾ç‰‡ id æ˜¯å…³é”®å­—ã€‚****
*   **ä¸€ä¸ªé—®é¢˜æ˜¯ï¼Œå¦‚æœè¿˜ä¸å­˜åœ¨å­—å…¸æ¡ç›®ï¼Œé‚£ä¹ˆæˆ‘ä»¬ä¸èƒ½å‘å®ƒé™„åŠ ä»»ä½• bbox å’Œ class åˆ—è¡¨ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬ä½¿ç”¨äº† Python çš„ defaultdictï¼Œä»£ç å¦‚ä¸‹ã€‚**

```
training_annotations = collections.defaultdict(lambda:[])
```

*   **å®ƒæ˜¯ä¸€ä¸ªå­—å…¸ï¼Œä½†æ˜¯å¦‚æœæˆ‘ä»¬æ­£åœ¨è®¿é—®ä¸€ä¸ªä¸å­˜åœ¨çš„é”®ï¼Œé‚£ä¹ˆ`defaultdict`ä¼šç¥å¥‡åœ°åˆ›å»ºä¸€ä¸ªå­—å…¸ï¼Œå¹¶è®¾ç½®å®ƒè‡ªå·±ç­‰äºå‡½æ•°è¿”å›çš„å€¼ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå®ƒæ˜¯ä¸€ä¸ªç©ºåˆ—è¡¨ã€‚å› æ­¤ï¼Œæ¯æ¬¡æˆ‘ä»¬è®¿é—®è®­ç»ƒæ³¨é‡Šä¸­çš„é”®æ—¶ï¼Œå¦‚æœå®ƒä¸å­˜åœ¨ï¼Œ`defaultdict`ä¼šåˆ›å»ºä¸€ä¸ªæ–°çš„ç©ºåˆ—è¡¨ï¼Œæˆ‘ä»¬å¯ä»¥å‘å®ƒè¿½åŠ å†…å®¹ã€‚**

****æœ‰ç”¨å›¾åƒç›¸å…³ä¿¡æ¯çš„æ±‡æ€»****

**è®©æˆ‘ä»¬æ·±å…¥äº†è§£ç‰¹å®šå›¾åƒçš„æ³¨é‡Šç»†èŠ‚ã€‚æ­£å¦‚æˆ‘ä»¬åœ¨ä¸‹é¢çš„å¿«ç…§ä¸­çœ‹åˆ°çš„ã€‚**

*   **æˆ‘ä»¬æ‹ä¸€å¼ ç‰¹å®šçš„ç…§ç‰‡ã€‚**
*   **è·å–å…¶æ³¨é‡Šï¼Œå³ BBox ä¸­å¯¹è±¡çš„**è¾¹ç•Œæ¡†å’Œç±»**ã€‚å®ƒè¡¨ç¤ºç±»ä¸­å­˜åœ¨å“ªäº›å¯¹è±¡ä»¥åŠè¿™äº›å¯¹è±¡çš„åæ ‡ã€‚**
*   **åœ¨ä¸‹é¢çš„ä¾‹å­ä¸­æ£€æŸ¥è¿™ä¸ªç±»æŒ‡çš„æ˜¯ä»€ä¹ˆã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œç±»åˆ«æ˜¯æ±½è½¦ã€‚**

**![](img/7e8f7a479049249915e59f6bc9b43473.png)**

**æœ‰äº›åº“é‡‡ç”¨ VOC æ ¼å¼çš„è¾¹ç•Œæ¡†ï¼Œå› æ­¤ ***bb_hw()*** å‡½æ•°æœ‰åŠ©äºå°†å°ºå¯¸é‡ç½®ä¸ºåŸå§‹æ ¼å¼:**

```
bb_voc = [155, 96, 196, 174]
bb_fastai = hw_bb(bb_voc) **# We won't be using the below function for now .**
def bb_hw(a): return np.array([a[1],a[0],a[3]-a[1]+1,a[2]-a[0]+1])
```

****1.4*ã€‚å›´ç»•å¯¹è±¡*ç»˜åˆ¶è¾¹ç•Œæ¡†****

**ç°åœ¨ï¼Œæˆ‘ä»¬å°†é‡ç‚¹æ”¾åœ¨åˆ›å»ºä¸€ä¸ªå›¾åƒå‘¨å›´çš„è¾¹ç•Œæ¡†ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å°†é€æ­¥æˆ–åœ¨å•ç‹¬çš„å‡½æ•°ä¸­åˆ›å»ºå›¾ã€‚æ¯ä¸€æ­¥éƒ½æœ‰æ˜ç¡®çš„ç›®çš„æ¥åˆ›é€ ä¸€ä¸ªæƒ…èŠ‚ã€‚è®©æˆ‘ä»¬çœ‹çœ‹æ¯ä¸€æ­¥çš„ç›®çš„ã€‚å‘å¸–è¯´æˆ‘ä»¬ä¼šæŠŠé‡ç‚¹æ”¾åœ¨æµé‡ä¸Šã€‚**

*   ****ä¸‹é¢çš„ä»£ç ç”¨äºè·å–è½´ï¼Œæˆ‘ä»¬å°†åœ¨å…¶ä¸Šç»˜åˆ¶å›¾åƒã€‚****

```
def show_img(im, figsize=None, ax=None):
**# The ax is used to pass in an axis object.** 
   if not ax: fig,ax = plt.subplots(figsize=figsize)
   ax.imshow(im)
   ax.get_xaxis().set_visible(False)
   ax.get_yaxis().set_visible(False)
   return ax
```

*   ****ä½¿ç”¨ä»¥ä¸‹ä»£ç åœ¨å›¾åƒä¸­çš„å¯¹è±¡å‘¨å›´ç»˜åˆ¶ä¸€ä¸ªçŸ©å½¢ã€‚****

```
def draw_rect(ax, b):
    patch = ax.add_patch(patches.Rectangle(b[:2], *b[-2:], fill=False, edgecolor='white', lw=2))
    draw_outline(patch, 4)**# *b[-2:] in the argument list is the splat operator . It passes b[-2],b[-1] as parameters. Its a shortcut.**
```

*   ****`**draw_outline()**`**ç”¨äºä½¿æ–‡æœ¬å¯è§ï¼Œä¸å—èƒŒæ™¯å½±å“ã€‚å› æ­¤ï¼Œè¿™é‡Œæˆ‘ä»¬ä½¿ç”¨é»‘è‰²è½®å»“çš„ç™½è‰²æ–‡æœ¬ï¼Œåä¹‹äº¦ç„¶ã€‚******

```
**def draw_outline(o, lw):
    o.set_path_effects([patheffects.Stroke(
        linewidth=lw, foreground='black'), patheffects.Normal()])**# foreground='black' means to create a black stroke around it.****
```

*   ****åœ¨è¾¹æ¡†é™„è¿‘ä»¥æ–‡æœ¬çš„å½¢å¼å†™ä¸‹å›¾åƒæ‰€å±çš„ç±»åˆ«ã€‚****

```
**def draw_text(ax, xy, txt, sz=14):
    text = ax.text(*xy, txt,
        verticalalignment='top', color='white', fontsize=sz, weight='bold')
    draw_outline(text, 1)**# Add text and draw outline around it.****
```

*   ****ä¸‹é¢æ˜¯å¦‚ä½•åœ¨å›¾åƒä¸­çš„ç‰©ä½“å‘¨å›´åˆ›å»ºä¸€ä¸ªè¾¹ç•Œæ¡†çš„æµç¨‹ã€‚****

```
****# Step 1 :- Returns the axis the image is on by calling the function     # show_img().**
ax = show_img(im)
**# Step 2 :- Convert the bounding box coordinates into proper format by   # calling the function bb_hw().**
b = bb_hw(im0_a[0])
**# Step 3:- Draw a rectangle /Bounding box around the object by calling   # the function draw_rect().**
draw_rect(ax, b)
**# Step 4:- Draw the text near the top left corner b[:2]** .
**# And it contains two things , the bounding box  and the class ,
# im0_a[1] is the class and to get the text , pass it into               # categories[im0_a[1]]
# by calling the function draw_text().**
draw_text(ax, b[:2], categories[im0_a[1]])** 
```

****è®©æˆ‘ä»¬ç”¨å¦‚ä¸‹æ‰€ç¤ºçš„å‡½æ•°æ¥æ€»ç»“æµç¨‹æ­¥éª¤****

```
**def draw_im(im, ann):
    ax = show_img(im, figsize=(16,8))
    for b,c in ann: **# Destructure the annotations into bbox and class**
        b = bb_hw(b) **# Convert it into appropriate coordinates**
        draw_rect(ax, b) **# Draw rectangle bbox around it.**
        draw_text(ax, b[:2], categories[c], sz=16) 
 **# Write some text around it**def draw_idx(i):
    im_a = training_annotations[i] **# Grab the annotations with the help of the image id.**
    im = open_image(IMG_PATH/training_filenames[i]) **# Open that Image**
    print(im.shape) **# Print its shape**
    draw_im(im, im_a) **# Call the draw and print its text**draw_idx(17) 
**# Draw an image of a particular index.****
```

****![](img/f575ceb33c97c56244d1d76ad2ab7644.png)****

****è®©æˆ‘ä»¬åœ¨è¿™é‡Œè¯¦ç»†æ€»ç»“ä¸€ä¸‹æµç¨‹:-****

*   ****`**draw_idx(17)**` è°ƒç”¨`**def draw_idx(i)**:`å‡½æ•°ï¼Œè¯¥å‡½æ•°è·å–å·²ä¼ é€’ç»™è¯¥å‡½æ•°çš„ 17 å·å›¾åƒçš„æ³¨é‡Šã€‚****
*   ******æ³¨æ„:-å¯¹è±¡çš„æ³¨é‡Šæ˜¯è¯¥å›¾åƒä¸­å¯¹è±¡çš„è¾¹ç•Œæ¡†ä»¥åŠè¯¥å¯¹è±¡æ‰€å±çš„ç±»ã€‚******
*   ****åœ¨`**def draw_idx(i)**` å‡½æ•°ä¸­ï¼Œè·å–æ³¨é‡Šåï¼Œæˆ‘ä»¬æ‰“å¼€å›¾åƒï¼Œæ‰“å°å‡ºå®ƒçš„å½¢çŠ¶ã€‚****
*   ****ç„¶åæˆ‘ä»¬ç”¨å›¾åƒåŠå…¶æ ‡æ³¨è°ƒç”¨`**def draw_im(im, im_a)**` å‡½æ•°ã€‚****
*   ****åœ¨è¿™ä¸ª`**def draw_im(im, im_a)**` å‡½æ•°ä¸­ï¼Œé¦–å…ˆæˆ‘ä»¬æ‰“å°å›¾åƒã€‚****
*   ****ç„¶ååœ¨ for å¾ªç¯ä¸­ï¼Œæˆ‘ä»¬éå†æ¯ä¸ªæ³¨é‡Šï¼Œå°†è¾¹ç•Œæ¡†å’Œç±»åˆ†åˆ«å­˜å‚¨åœ¨ b å’Œ c ä¸­ã€‚è¿™ä¹Ÿç§°ä¸ºèµ‹å€¼çš„ææ„ã€‚****
*   ****ä½¿ç”¨æ­¤`**bb_hw(b)**` åŠŸèƒ½å°†è¾¹ç•Œæ¡†åæ ‡è½¬æ¢æˆåˆé€‚çš„åæ ‡ï¼Œå³å·¦ä¸Šè§’å’Œå³ä¸‹è§’åæ ‡ã€‚****
*   ****`**draw_rect(ax, b)**` **:-** ä½¿ç”¨è¿™ä¸ªå‡½æ•°ï¼Œæˆ‘ä»¬åœ¨è¾¹ç•Œæ¡†å‘¨å›´ç”»ä¸€ä¸ªçŸ©å½¢ã€‚****
*   ****`**draw_text(ax, b[:2], categories[c], sz=16)**` **:-** ä½¿ç”¨è¿™ä¸ªåŠŸèƒ½ï¼Œæˆ‘ä»¬æ­£åœ¨å†™ä¸€äº›æ–‡å­—ã€‚****

****è¿™å°±æ˜¯æˆ‘ä»¬åœ¨å›¾åƒä¸­å®šä½ç‰©ä½“çš„æ–¹å¼ã€‚ä¸‹ä¸€æ­¥æ˜¯å¯¹å›¾åƒä¸­æœ€å¤§çš„é¡¹ç›®è¿›è¡Œåˆ†ç±»ã€‚æˆ‘ä»¬å°†åœ¨[ä¸‹ä¸€ç¯‡åšæ–‡](https://medium.com/p/2deafc911ce7/edit)ä¸­è¯¦ç»†è®¨è®ºä¸‹ä¸€æ­¥ã€‚****

****å¤§å£°ç–¾å‘¼ [Anwesh Satapathy](/@anweshsatapathy) å’Œ [Sharwon Pius](https://twitter.com/shar1pius) ç”¨ç®€å•çš„æ–¹å¼è¯´æ˜äº†è¿™ä¸ªé—®é¢˜ã€‚è¯·æŸ¥çœ‹ä»–çš„ [github Repo](https://github.com/AI6-Bangalore-Chapter/2018-cycle-2/tree/master/Sessions/Session_12) å’Œå•ä¸ªå¯¹è±¡æ£€æµ‹çš„ç®€åŒ–è·¯çº¿å›¾ã€‚****

****å¦‚æœæ‚¨æœ‰ä»»ä½•ç–‘é—®ï¼Œè¯·éšæ—¶åœ¨ twitter ä¸Šæå‡º [@ashiskumarpanda](https://twitter.com/ashiskumarpanda) æˆ–åœ¨ fastai è®ºå›ä¸ŠæŸ¥çœ‹ã€‚****

*******å¦‚æœçœ‹åˆ°äº†ğŸ‘ ğŸ‘æŒ‰é’®ï¼Œå¦‚æœä½ å–œæ¬¢è¿™ç¯‡æ–‡ç« ï¼Œè¯·éšæ„åšä½ éœ€è¦åšçš„ğŸ˜„ğŸ˜„ğŸ˜„ğŸ˜„ğŸ˜„ã€‚*******

****è¢«æ°ç‘ç±³Â·éœåå¾·èµè¯†çš„æ„Ÿè§‰çœŸçš„å¾ˆå¥½ã€‚çœ‹çœ‹ä»–å¯¹æˆ‘çš„ Fast.ai ç¬¬ä¸€éƒ¨åˆ†åšå®¢çš„çœ‹æ³•ã€‚ä¸€å®šè¦çœ‹ä¸€çœ‹ã€‚****