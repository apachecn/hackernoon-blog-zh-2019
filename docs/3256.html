<html>
<head>
<title>Preventing AI Systems from Amplifying Bias with Adversarial Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">é˜²æ­¢äººå·¥æ™ºèƒ½ç³»ç»Ÿé€šè¿‡å¯¹æŠ—æ€§å­¦ä¹ æ”¾å¤§åè§</h1>
<blockquote>åŸæ–‡ï¼š<a href="https://medium.com/hackernoon/preventing-ai-system-from-amplifying-bias-with-adversarial-learning-bd5e224f5a31#2019-05-23">https://medium.com/hackernoon/preventing-ai-system-from-amplifying-bias-with-adversarial-learning-bd5e224f5a31#2019-05-23</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><div class=""><h2 id="4ed4" class="pw-subtitle-paragraph ir ht hu bd b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ek translated">å¯¹æŠ—å­¦ä¹ ä¸­åè§çš„ä»‹ç»ã€åŸå› åŠè§£å†³æ–¹æ³•</h2></div><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="fe ff jj"><img src="../Images/0771f6192054ef5a05f1832be09ca88d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*PetwS1-bqFAvlhOG.png"/></div></div></figure><p id="0d9c" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated"><strong class="jx hv">è¯´åˆ°æ”¾å¤§åå·®ï¼Œæˆ‘ä»¬é¦–å…ˆæƒ³åˆ°çš„é—®é¢˜æ˜¯ï¼ŒAI ç³»ç»Ÿæ˜¯å¦‚ä½•æ”¾å¤§åå·®çš„ï¼Ÿ</strong></p><p id="c7da" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">åˆ¤åˆ«æˆ–ç”Ÿæˆæ¨¡å‹æ˜¯åå·®æ”¾å¤§çš„åŸå› ã€‚å› ä¸ºåˆ¤åˆ«æ¨¡å‹æ›´åƒæ˜¯â€œé»‘ç®±â€,åªå­¦ä¹ å›ç­”ç‰¹å®šçš„è®­ç»ƒæ•°æ®é›†ã€‚</p><p id="3f36" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated"><strong class="jx hv">ä¸‹ä¸€ä¸ªé—®é¢˜æ˜¯ï¼Œä»€ä¹ˆæ˜¯åˆ¤åˆ«æ¨¡å‹ï¼Œå®ƒæ˜¯å¦‚ä½•å¯¼è‡´åè§çš„ï¼Ÿ</strong></p><p id="2bab" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">åˆ¤åˆ«æ¨¡å‹ä¹Ÿç§°ä¸ºæ¡ä»¶æ¨¡å‹ï¼Œå®ƒè¯•å›¾ä»…æ ¹æ®è§‚å¯Ÿåˆ°çš„æ•°æ®æ¥è®­ç»ƒæ¨¡å‹ï¼ŒåŒæ—¶å­¦ä¹ å¦‚ä½•ä»ç»™å®šçš„ç»Ÿè®¡æ•°æ®ä¸­è¿›è¡Œåˆ†ç±»ã€‚åˆ¤åˆ«æ¨¡å‹ï¼Œå¦‚ç¥ç»ç½‘ç»œã€é€»è¾‘å›å½’ã€SVMã€æ¡ä»¶éšæœºåœºã€‚</p><p id="2ede" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated"><strong class="jx hv">é‚£ä¹ˆï¼Œäººå·¥æ™ºèƒ½ç®—æ³•æ˜¯å¦‚ä½•æ”¾å¤§åå·®çš„ï¼Ÿ</strong></p><p id="54d7" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated"><strong class="jx hv">ç°åœ¨ï¼Œè®©æˆ‘ä»¬ä»¥å•è¯åµŒå…¥åå·®ä¸ºä¾‹ï¼Œå®ƒæ˜¯æ”¾å¤§åå·®çš„æ¥æºã€‚</strong></p><p id="ca61" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">æœºå™¨å­¦ä¹ ç³»ç»Ÿçš„åŠ›é‡ä¸ä»…é¢„ç¤ºç€å·¨å¤§çš„æŠ€æœ¯è¿›æ­¥ï¼Œä¹Ÿå¸¦æ¥äº†ç¤¾ä¼šå±å®³çš„é£é™©ã€‚æµè¡Œçš„å•è¯åµŒå…¥ç®—æ³•è¡¨ç°å‡ºåˆ»æ¿åè§ï¼Œä¾‹å¦‚æ€§åˆ«åè§ã€‚è¿™äº›ç®—æ³•åœ¨æœºå™¨å­¦ä¹ ç³»ç»Ÿä¸­çš„å¹¿æ³›ä½¿ç”¨ï¼Œä»è‡ªåŠ¨ç¿»è¯‘æœåŠ¡åˆ°ç®€å†æ‰«æä»ªï¼Œå¯ä»¥åœ¨é‡è¦çš„èƒŒæ™¯ä¸‹æ”¾å¤§åˆ»æ¿å°è±¡ã€‚å°½ç®¡å·²ç»å¼€å‘äº†æµ‹é‡è¿™äº›åå·®å’Œæ”¹å˜å•è¯åµŒå…¥ä»¥å‡è½»å®ƒä»¬çš„æœ‰åå·®è¡¨ç¤ºçš„æ–¹æ³•ï¼Œä½†æ˜¯ç¼ºä¹å¯¹å•è¯åµŒå…¥åå·®å¦‚ä½•ä¾èµ–äºè®­ç»ƒæ•°æ®çš„ç†è§£ã€‚ç»™å®šåœ¨è¯­æ–™åº“ä¸Šè®­ç»ƒçš„å•è¯åµŒå…¥ï¼Œç‰¹å®šåå·®åº¦é‡æ–¹æ³•è¯†åˆ«å¯¹è¯­æ–™åº“çš„æ‰°åŠ¨å°†å¦‚ä½•å½±å“æ‰€å¾—åµŒå…¥çš„åå·®ã€‚è¿™å¯ä»¥ç”¨æ¥è¿½æº¯å•è¯åµŒå…¥åå·®çš„æ¥æºï¼Œè¿½æº¯åˆ°åŸå§‹è®­ç»ƒæ–‡æ¡£ã€‚</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div class="fe ff kr"><img src="../Images/6b7d9065f0436da4f214de619a8997eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/0*NxfVoyaCDC0dlLHK"/></div><figcaption class="ks kt fg fe ff ku kv bd b be z ek">Fig shows how certain cultural context of information learned by Athe I system leads to bias</figcaption></figure><p id="5524" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated"><strong class="jx hv">å®ƒä»¬å¦‚ä½•å½±å“ï¼Ÿ</strong></p><p id="6fa2" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">å¦‚æœæ‰§è¡Œåˆ†ç±»ä»»åŠ¡ï¼Œä»–ä»¬å¯èƒ½ä¼šæ¥å—æœ€å¤§åŒ–åˆ†ç±»å‡†ç¡®æ€§çš„åŸ¹è®­ã€‚è¿™æ„å‘³ç€æ¨¡å‹å°†åˆ©ç”¨ä»»ä½•æœ‰åŠ©äºæé«˜æ•°æ®é›†å‡†ç¡®æ€§çš„ä¿¡æ¯ï¼Œå°¤å…¶æ˜¯æ•°æ®ä¸­å­˜åœ¨çš„ä»»ä½•åå·®ã€‚</p><p id="a653" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">ä¾‹å¦‚ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹ä¸€ä¸ªå®æ—¶è‡ªåŠ¨åŒ–æ‹›è˜å¹³å°çš„æ¡ˆä¾‹ç ”ç©¶ï¼Œå®ƒæ˜¯å¦‚ä½•å½±å“å€™é€‰äººè€Œä¸è¿›å…¥å·¥ä½œçš„ã€‚</p><p id="a86b" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated"><strong class="jx hv">â€œäºšé©¬é€ŠæŠ›å¼ƒäº†äººå·¥æ™ºèƒ½æ‹›è˜å·¥å…·ï¼Œè¯¥å·¥å…·åçˆ±ä»äº‹æŠ€æœ¯å·¥ä½œçš„ç”·æ€§ã€‚â€</strong></p><p id="c59d" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated"><strong class="jx hv">æ€ä¹ˆå‘ç”Ÿçš„ï¼Ÿ</strong></p><p id="806f" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">è¯¥å…¬å¸çš„å®éªŒæ€§æ‹›è˜å·¥å…·ä½¿ç”¨äººå·¥æ™ºèƒ½ç»™æ±‚èŒè€…æ‰“åˆ†ï¼Œä»ä¸€é¢—æ˜Ÿåˆ°äº”é¢—æ˜Ÿä¸ç­‰ï¼Œå°±åƒè´­ç‰©è€…åœ¨äºšé©¬é€Šä¸Šç»™äº§å“æ‰“åˆ†ä¸€æ ·ã€‚â€œä»–ä»¬çœŸçš„å¸Œæœ›å®ƒæ˜¯ä¸€ä¸ªå¼•æ“ï¼Œæˆ‘ä¼šç»™ä½  100 ä»½ç®€å†ï¼Œå®ƒä¼šåˆ†å‡ºå‰äº”åï¼Œæˆ‘ä»¬ä¼šé›‡ç”¨ä»–ä»¬ã€‚â€</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="fe ff kw"><img src="../Images/bb0588cac6d4b97fa18fa971fd7d3940.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*trNOqGXv9OAvEk1I84ozxQ.png"/></div></div><figcaption class="ks kt fg fe ff ku kv bd b be z ek">Amazon recruitment System bias against women</figcaption></figure><p id="c9fe" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">ä½†åˆ° 2015 å¹´ï¼Œè¯¥å…¬å¸æ„è¯†åˆ°å…¶æ–°ç³»ç»Ÿå¹¶æ²¡æœ‰ä»¥æ€§åˆ«ä¸­ç«‹çš„æ–¹å¼å¯¹è½¯ä»¶å¼€å‘å·¥ä½œå’Œå…¶ä»–æŠ€æœ¯èŒä½çš„å€™é€‰äººè¿›è¡Œè¯„çº§ã€‚è¿™æ˜¯å› ä¸ºäºšé©¬é€Šæ‹›è˜å¹³å°ä¸­çš„â€œ<strong class="jx hv">äººå·¥æ™ºèƒ½æ¨¡å‹â€æ˜¯é€šè¿‡è§‚å¯Ÿ 10 å¹´é—´æäº¤ç»™è¯¥å…¬å¸çš„ç®€å†æ¨¡å¼æ¥è®­ç»ƒç”³è¯·äººçš„ã€‚å¤§å¤šæ•°æ¥è‡ªç”·æ€§ï¼Œè¿™å¯¼è‡´äº†ç”·æ€§åœ¨æ•´ä¸ªæ‹›è˜å¹³å°ä¸Šçš„ä¸»å¯¼åœ°ä½ã€‚</strong></p><p id="f4cd" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated"><strong class="jx hv">å¦‚ä½•å¤„ç†äººå·¥æ™ºèƒ½(NLP)ç³»ç»Ÿä¸­æ€§åˆ«ä¸­ç«‹æ–¹å¼çš„åè§ï¼Ÿ</strong></p><p id="1d09" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">å•è¯åµŒå…¥æ¨¡å‹å·²ç»æˆä¸ºå¹¿æ³›çš„è‡ªç„¶è¯­è¨€å¤„ç†(NLP)åº”ç”¨ä¸­çš„åŸºæœ¬ç»„ä»¶ã€‚ç„¶è€Œï¼Œåœ¨äººç±»ç”Ÿæˆçš„è¯­æ–™åº“ä¸Šè®­ç»ƒçš„åµŒå…¥å·²ç»è¢«è¯æ˜ç»§æ‰¿äº†åæ˜ ç¤¾ä¼šç»“æ„çš„å¼ºçƒˆçš„æ€§åˆ«åˆ»æ¿å°è±¡ã€‚</p><p id="91ff" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">åµŒå…¥æ˜¯å°†ç¦»æ•£å˜é‡(ä¾‹å¦‚å•è¯ã€åœ°åŒºã€URL)æŠ•å½±åˆ°å¤šç»´å®å€¼ç©ºé—´çš„å¼ºå¤§æœºåˆ¶ã€‚å·²ç»å¼€å‘äº†å‡ ç§å¼ºæœ‰åŠ›çš„æ–¹æ³•æ¥å­¦ä¹ åµŒå…¥ã€‚ä¸€ä¸ªä¾‹å­æ˜¯è·³æ ¼ç®—æ³•ã€‚åœ¨è¯¥ç®—æ³•ä¸­ï¼Œå‘¨å›´çš„ä¸Šä¸‹æ–‡ç”¨äºé¢„æµ‹å•è¯çš„å­˜åœ¨ã€‚ä¸å¹¸çš„æ˜¯ï¼Œè®¸å¤šçœŸå®ä¸–ç•Œçš„æ–‡æœ¬æ•°æ®éƒ½æœ‰ä¸€ä¸ªå¾®å¦™çš„åå·®ï¼Œæœºå™¨å­¦ä¹ ç®—æ³•ä¼šéšå¼åœ°å°†å®ƒåŒ…å«åœ¨ä»è¯¥æ•°æ®åˆ›å»ºçš„åµŒå…¥ä¸­ã€‚è¿™ç§åå·®å¯ä»¥é€šè¿‡ä½¿ç”¨å­¦ä¹ åˆ°çš„åµŒå…¥æ¥æ‰§è¡Œå•è¯ç±»æ¯”ä»»åŠ¡æ¥è¯´æ˜</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="fe ff kx"><img src="../Images/1867a42ee6876ce59b742494526a76ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*zo1-EuxzdHUABYup.png"/></div></div></figure><p id="01a3" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">ç°åœ¨ï¼Œè®©æˆ‘ä»¬è®¨è®ºä¸€ä¸‹å‡è½»åè§çš„æœ€æœ‰æ•ˆçš„å¯¹æŠ—æ€§å­¦ä¹ ã€‚</p><h1 id="da57" class="ky kz hu bd la lb lc ld le lf lg lh li ja lj jb lk jd ll je lm jg ln jh lo lp dt translated">å¯¹æŠ—æ€§å­¦ä¹ å¦‚ä½•æœ‰åŠ©äºå‡è½»åè§ï¼Ÿ</h1><p id="013c" class="pw-post-body-paragraph jv jw hu jx b jy lq iv ka kb lr iy kd ke ls kg kh ki lt kk kl km lu ko kp kq hn dt translated">å¯¹æŠ—æ³•æ¶ˆé™¤äº†åµŒå…¥ä¸­çš„ä¸€äº›åè§ï¼Œå®ƒåŸºäºè¿™æ ·ä¸€ç§æ€æƒ³ï¼Œå³é‚£äº›åµŒå…¥æ—¨åœ¨ç”¨äºé¢„æµ‹åŸºäºè¾“å…¥ğ‘‹çš„ä¸€äº›ç»“æœğ‘Œï¼Œä½†æ˜¯åœ¨å…¬å¹³çš„ä¸–ç•Œä¸­ï¼Œè¯¥ç»“æœåº”è¯¥ä¸ä¸€äº›å—ä¿æŠ¤çš„å˜é‡ğ‘.å®Œå…¨æ— å…³å¦‚æœæ˜¯è¿™æ ·çš„è¯ï¼Œé‚£ä¹ˆäº†è§£ğ‘Œå¹¶ä¸ä¼šå¸®åŠ©ä½ æ›´å¥½åœ°é¢„æµ‹ğ‘ã€‚è¿™ä¸ªåŸç†å¯ä»¥ç›´æ¥è½¬åŒ–ä¸ºå¦‚ä¸‹å›¾æ‰€ç¤ºçš„ä¸¤ä¸ªä¸²è”ç½‘ç»œã€‚ç¬¬ä¸€æ¬¡å°è¯•ä½¿ç”¨ğ‘‹ä½œä¸ºè¾“å…¥æ¥é¢„æµ‹ğ‘Œã€‚ç¬¬äºŒæ¬¡å°è¯•ä½¿ç”¨ğ‘Œçš„é¢„æµ‹å€¼æ¥é¢„æµ‹ğ‘.å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œ</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="fe ff lv"><img src="../Images/8c3371846b4120e84dbad6e99f29deb0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XpohoM7Q-m6uNYvMru044g.png"/></div></div><figcaption class="ks kt fg fe ff ku kv bd b be z ek">The architecture of Adversarial network</figcaption></figure><p id="4959" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">ç„¶è€Œï¼Œç®€å•åœ°è®­ç»ƒåŸºäºâˆ‡ğ‘Šğ¿1 çš„ w ä¸­çš„æƒé‡å’ŒåŸºäºâˆ‡ğ‘ˆğ¿2 çš„ğ‘ˆä¸­çš„æƒé‡å®é™…ä¸Šä¸ä¼šå®ç°æ— åçš„æ¨¡å‹ã€‚ä¸ºäº†åšåˆ°è¿™ä¸€ç‚¹ï¼Œä½ éœ€è¦åœ¨ğ‘Š's æ›´æ–°å‡½æ•°ä¸­åŠ å…¥è¿™æ ·ä¸€ä¸ªæ¦‚å¿µï¼Œå³ğ‘ˆåœ¨é¢„æµ‹ğ‘.æ—¶åº”è¯¥ä¸ä¼šæ¯”æœºä¼šæ›´å¥½ä½ å¯ä»¥å®ç°è¿™ä¸€ç‚¹çš„æ–¹å¼ç±»ä¼¼äºç”Ÿæˆæ•Œå¯¹ç½‘ç»œ(GANs) ( <a class="ae lw" href="http://papers.nips.cc/paper/5423-generative-adversarial-nets" rel="noopener ugc nofollow" target="_blank"> Goodfellow ç­‰äºº 2014 </a>)è®­ç»ƒå…¶ç”Ÿæˆå™¨çš„æ–¹å¼ã€‚</p><p id="7d8c" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">é™¤äº†âˆ‡ğ‘Šğ¿1ï¼Œä½ è¿˜æŠŠå¯¹âˆ‡ğ‘Šğ¿2 çš„å¦å®šçº³å…¥äº†ğ‘Š's çš„æ›´æ–°å‡½æ•°ã€‚ç„¶è€Œï¼Œæœ‰å¯èƒ½âˆ‡ğ‘Šğ¿1 æ­£åœ¨æ”¹å˜ğ‘Šï¼Œé€šè¿‡ä½¿ç”¨ä½ è¯•å›¾ä¿æŠ¤çš„æœ‰åè§çš„ä¿¡æ¯æ¥æé«˜å‡†ç¡®æ€§ã€‚ä¸ºäº†é¿å…è¿™ä¸€ç‚¹ï¼Œä½ è¿˜åŠ å…¥äº†ä¸€ä¸ªæœ¯è¯­ï¼Œé€šè¿‡å°†âˆ‡ğ‘Šğ¿1 çš„æˆåˆ†æŠ•å°„åˆ°âˆ‡ğ‘Šğ¿2.ï¼Œæ¥ç§»é™¤å®ƒä¸€æ—¦å°†è¿™ä¸¤ä¸ªæœ¯è¯­åˆå¹¶ï¼Œğ‘Šçš„æ›´æ–°å‡½æ•°å°±å˜æˆäº†:</p><p id="ea86" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt">âˆ‡ğ‘Šğ¿1âˆ’ğ‘ğ‘Ÿğ‘œğ‘—(âˆ‡ğ‘Šğ¿2)âˆ‡ğ‘Šğ¿1âˆ’âˆ‡ğ‘Šğ¿2</p><p id="667d" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">å¯¹å¦‚ä½•å°†æ•Œå¯¹ç½‘ç»œåˆå¹¶åˆ°æœºå™¨å­¦ä¹ æ¨¡å‹ä¸­çš„æè¿°æ˜¯éå¸¸é€šç”¨çš„ï¼Œå› ä¸ºè¯¥æŠ€æœ¯é€šå¸¸é€‚ç”¨äºä»»ä½•ç±»å‹çš„ç³»ç»Ÿï¼Œè¿™äº›ç³»ç»Ÿå¯ä»¥æ ¹æ®é¢„æµ‹ğ‘Œçš„è¾“å…¥ğ‘‹æ¥æè¿°ï¼Œä½†æ˜¯å¯èƒ½åŒ…å«å…³äºå—ä¿æŠ¤å˜é‡ğ‘.çš„ä¿¡æ¯åªè¦ä½ èƒ½æ„é€ ç›¸å…³çš„æ›´æ–°å‡½æ•°ï¼Œä½ å°±èƒ½åº”ç”¨è¿™ç§æŠ€æœ¯ã€‚ç„¶è€Œï¼Œè¿™å¹¶ä¸èƒ½å‘Šè¯‰ä½ å¤ªå¤šå…³äºğ‘‹ã€ğ‘Œå’Œğ‘.çš„æœ¬è´¨åœ¨å•è¯ç±»æ¯”ä»»åŠ¡ä¸­ï¼Œğ‘‹ =ğµ+ğ¶âˆ’ğ´å’Œğ‘Œ=ğ·.ä¸è¿‡ï¼Œè¦å¼„æ¸…æ¥šğ‘åº”è¯¥æ˜¯ä»€ä¹ˆæ ·å­ï¼Œè¦ç¨å¾®å¤æ‚ä¸€ç‚¹ã€‚ä¸ºæ­¤ï¼Œè¯·å‚è€ƒ Bulokbasi ç­‰äººçš„ä¸€ç¯‡è®ºæ–‡ã€‚è‰¾å°”ã€‚ä»–ä»¬å¼€å‘äº†ä¸€ç§æ— ç›‘ç£çš„æ–¹æ³•æ¥ä»å•è¯åµŒå…¥ä¸­å»é™¤æ€§åˆ«è¯­ä¹‰ã€‚</p><p id="96a3" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated"><strong class="jx hv">ç°åœ¨ï¼Œæˆ‘ä»¬å°†æ·±å…¥æ¢è®¨ä½¿ç”¨å¯¹æŠ—æ€§å­¦ä¹ æ¥å‡è½»åè§çš„å®ç°éƒ¨åˆ†</strong></p><p id="004d" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">ç¬¬ä¸€æ­¥æ˜¯é€‰æ‹©ä¸è¯•å›¾æ¶ˆé™¤çš„åè§ç±»å‹ç›¸å…³çš„è¯å¯¹ã€‚å°±æ€§åˆ«è€Œè¨€ï¼Œé€‰æ‹©åƒâ€œç”·äººâ€ã€â€œå¥³äººâ€ã€â€œç”·å­©â€ã€â€œå¥³å­©â€è¿™æ ·çš„è¯å¯¹ï¼Œå®ƒä»¬åœ¨è¯­ä¹‰ä¸Šçš„å”¯ä¸€åŒºåˆ«å°±æ˜¯æ€§åˆ«ã€‚è¿™äº›è¯å¯¹å¯ä»¥è®¡ç®—å®ƒä»¬çš„åµŒå…¥ä¹‹é—´çš„å·®å¼‚ï¼Œä»¥åœ¨åµŒå…¥çš„è¯­ä¹‰ç©ºé—´ä¸­äº§ç”Ÿå¤§è‡´å¹³è¡Œäºæ€§åˆ«è¯­ä¹‰çš„å‘é‡ã€‚å¯¹è¿™äº›å‘é‡æ‰§è¡Œä¸»æˆåˆ†åˆ†æ(PCA ),ç„¶åç»™å‡ºç”±æ‰€æä¾›çš„æ€§åˆ«åŒ–å•è¯å¯¹å®šä¹‰çš„æ€§åˆ«è¯­ä¹‰çš„ä¸»è¦æˆåˆ†ã€‚å› æ­¤ï¼Œè®©æˆ‘ä»¬å®šä¹‰ç”¨äºæ‰§è¡ŒåµŒå…¥çš„ä¸»è¦ç»„ä»¶çš„å‡½æ•°ï¼Œ</p><pre class="jk jl jm jn fq lx ly lz ma aw mb dt"><span id="c16c" class="mc kz hu ly b fv md me l mf mg">def find_gender_direction(embed,<br/>                          indices):<br/>  """Finds and returns a 'gender direction'."""<br/>  pairs = [<br/>      ("woman", "man"),<br/>      ("her", "his"),<br/>      ("she", "he"),<br/>      ("aunt", "uncle"),<br/>      ("niece", "nephew"),<br/>      ("daughters", "sons"),<br/>      ("mother", "father"),<br/>      ("daughter", "son"),<br/>      ("granddaughter", "grandson"),<br/>      ("girl", "boy"),<br/>      ("stepdaughter", "stepson"),<br/>      ("mom", "dad"),<br/>  ]<br/>  m = []<br/>  for wf, wm in pairs:<br/>    m.append(embed[indices[wf]] - embed[indices[wm]])<br/>  m = np.array(m)</span><span id="8976" class="mc kz hu ly b fv mh me l mf mg"># the next three lines are just a PCA.<br/>  m = np.cov(np.array(m).T)<br/>  evals, evecs = np.linalg.eig(m)<br/>  return _np_normalize(np.real(evecs[:, np.argmax(evals)]))</span><span id="6048" class="mc kz hu ly b fv mh me l mf mg"># Using the embeddings, find the gender vector.<br/>gender_direction = find_gender_direction(embed, indices)<br/>print "gender direction: %s" % str(gender_direction.flatten())</span></pre><p id="2102" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">ä¸€æ—¦å®Œæˆäº†åµŒå…¥å·®å¼‚çš„ç¬¬ä¸€ä¸ªä¸»æˆåˆ†ï¼Œå¼€å§‹æŠŠå•è¯çš„åµŒå…¥æŠ•å°„åˆ°å®ƒä¸Šé¢ã€‚è¿™ä¸ªé¢„æµ‹å¯ä»¥ä½œä¸ºå¯¹æ‰‹è¯•å›¾æ ¹æ®ğ‘Œ.çš„é¢„æµ‹å€¼é¢„æµ‹çš„å—ä¿æŠ¤å˜é‡ğ‘ç°åœ¨è®©æˆ‘ä»¬æ¥çœ‹çœ‹å¯¹æ€§åˆ«ç»´åº¦æœ‰æœ€å¤§è´Ÿé¢å½±å“çš„å•è¯ã€‚</p><pre class="jk jl jm jn fq lx ly lz ma aw mb dt"><span id="866f" class="mc kz hu ly b fv md me l mf mg">words = set()<br/>for a in analogies:<br/>  words.update(a)</span><span id="4666" class="mc kz hu ly b fv mh me l mf mg">df = pd.DataFrame(data={"word": list(words)})<br/>df["gender_score"] = df["word"].map(<br/>    lambda w: client.word_vec(w).dot(gender_direction))<br/>df.sort_values(by="gender_score", inplace=True)<br/>print df.head(10)</span></pre><p id="28e4" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">ç°åœ¨è®©æˆ‘ä»¬æ¥çœ‹çœ‹é‚£äº›åœ¨æ€§åˆ«ç»´åº¦ä¸Šæœ‰æœ€å¤§<em class="mi">æ­£é¢</em>æŠ•å°„çš„å•è¯ã€‚</p><pre class="jk jl jm jn fq lx ly lz ma aw mb dt"><span id="2625" class="mc kz hu ly b fv md me l mf mg">df.sort_values(by="gender_score", inplace=True, ascending=False)<br/>print df.head(10)</span></pre><h1 id="cb48" class="ky kz hu bd la lb lc ld le lf lg lh li ja lj jb lk jd ll je lm jg ln jh lo lp dt translated">è®­ç»ƒæ¨¡å‹</h1><p id="2cfb" class="pw-post-body-paragraph jv jw hu jx b jy lq iv ka kb lr iy kd ke ls kg kh ki lt kk kl km lu ko kp kq hn dt translated">è®­ç»ƒæ•Œå¯¹ç½‘ç»œæ˜¯å›°éš¾çš„ã€‚ä»–ä»¬å¾ˆæ•æ„Ÿï¼Œå¦‚æœæ¥è§¦çš„æ–¹å¼ä¸å¯¹ï¼Œä»–ä»¬å¾ˆå¿«å°±ä¼šçˆ†å‘ã€‚å¿…é¡»éå¸¸å°å¿ƒåœ°ä»¥è¶³å¤Ÿæ…¢çš„é€Ÿåº¦è®­ç»ƒä¸¤ä¸ªæ¨¡å‹ï¼Œä»¥ä¾¿æ¨¡å‹ä¸­çš„å‚æ•°ä¸ä¼šå‘æ•£ã€‚å®é™…ä¸Šï¼Œè¿™é€šå¸¸éœ€è¦æ˜¾è‘—é™ä½åˆ†ç±»å™¨å’Œå¯¹æ‰‹çš„æ­¥é•¿ã€‚å°†å¯¹æ‰‹çš„å‚æ•°åˆå§‹åŒ–ä¸ºæå°ä¹Ÿå¯èƒ½æ˜¯æœ‰ç›Šçš„ï¼Œä»¥ç¡®ä¿åˆ†ç±»å™¨ä¸ä¼šè¿‡åº¦é€‚åº”ç‰¹å®šçš„(æ¬¡ä¼˜)å¯¹æ‰‹(è¿™ç§è¿‡åº¦é€‚åº”ä¼šå¾ˆå¿«å¯¼è‡´å‘æ•£ï¼).ä¹Ÿæœ‰å¯èƒ½çš„æ˜¯ï¼Œå¦‚æœåˆ†ç±»å™¨å¤ªæ“…é•¿äºå¯¹å¯¹æ‰‹éšè—å—ä¿æŠ¤çš„å˜é‡ï¼Œé‚£ä¹ˆå¯¹æ‰‹å°†å¼ºåŠ å‘æ•£çš„æ›´æ–°ä»¥åŠªåŠ›æé«˜å…¶æ€§èƒ½ã€‚è§£å†³æ–¹æ³•æœ‰æ—¶æ˜¯å®é™…ä¸Šå¢åŠ å¯¹æ‰‹çš„å­¦ä¹ é€Ÿç‡ä»¥é˜²æ­¢å‘æ•£(è¿™åœ¨å¤§å¤šæ•°å­¦ä¹ ç³»ç»Ÿä¸­å‡ ä¹æ˜¯é—»æ‰€æœªé—»çš„)ã€‚åœ¨æˆ‘çš„<a class="ae lw" href="https://github.com/rashmimarganiatgithub/preventing_bias_adversarial" rel="noopener ugc nofollow" target="_blank"> <strong class="jx hv"> GitHub </strong> </a> <strong class="jx hv">ï¼Œ</strong>ä¸­å¯ä»¥æ‰¾åˆ°ç›¸åŒçš„å•è¯åµŒå…¥çš„å»åç½®æ¨¡å‹ï¼Œè¯·æŸ¥çœ‹å®ƒä»¥é‡ç°å®éªŒã€‚ä¸‹é¢æ˜¯è®­ç»ƒæ¨¡å‹çš„ä»£ç ã€‚</p><pre class="jk jl jm jn fq lx ly lz ma aw mb dt"><span id="ffe8" class="mc kz hu ly b fv md me l mf mg">class AdversarialEmbeddingModel(object):<br/>  """A model for doing adversarial training of embedding models."""</span><span id="f37b" class="mc kz hu ly b fv mh me l mf mg">def __init__(self, client,<br/>               data_p, embed_dim, projection,<br/>               projection_dims, pred):<br/>    """Creates a new AdversarialEmbeddingModel.</span><span id="98b9" class="mc kz hu ly b fv mh me l mf mg">Args:<br/>      client: The (possibly biased) embeddings.<br/>      data_p: Placeholder for the data.<br/>      embed_dim: Number of dimensions used in the embeddings.<br/>      projection: The space onto which we are "projecting".<br/>      projection_dims: Number of dimensions of the projection.<br/>      pred: Prediction layer.<br/>    """<br/>    # load the analogy vectors as well as the embeddings<br/>    self.client = client<br/>    self.data_p = data_p<br/>    self.embed_dim = embed_dim<br/>    self.projection = projection<br/>    self.projection_dims = projection_dims<br/>    self.pred = pred</span><span id="3b99" class="mc kz hu ly b fv mh me l mf mg">def nearest_neighbors(self, sess, in_arr,<br/>                        k):<br/>    """Finds the nearest neighbors to a vector.</span><span id="7f06" class="mc kz hu ly b fv mh me l mf mg">Args:<br/>      sess: Session to use.<br/>      in_arr: Vector to find nearest neighbors to.<br/>      k: Number of nearest neighbors to return<br/>    Returns:<br/>      List of up to k pairs of (word, score).<br/>    """<br/>    v = sess.run(self.pred, feed_dict={self.data_p: in_arr})<br/>    return self.client.similar_by_vector(v.flatten().astype(float), topn=k)</span><span id="d048" class="mc kz hu ly b fv mh me l mf mg">def write_to_file(self, sess, f):<br/>    """Writes a model to disk."""<br/>    np.savetxt(f, sess.run(self.projection))</span><span id="dbe9" class="mc kz hu ly b fv mh me l mf mg">def read_from_file(self, sess, f):<br/>    """Reads a model from disk."""<br/>    loaded_projection = np.loadtxt(f).reshape(<br/>        [self.embed_dim, self.projection_dims])<br/>    sess.run(self.projection.assign(loaded_projection))</span><span id="f563" class="mc kz hu ly b fv mh me l mf mg">def fit(self,<br/>          sess,<br/>          data,<br/>          data_p,<br/>          labels,<br/>          labels_p,<br/>          protect,<br/>          protect_p,<br/>          gender_direction,<br/>          pred_learning_rate,<br/>          protect_learning_rate,<br/>          protect_loss_weight,<br/>          num_steps,<br/>          batch_size,<br/>          debug_interval=1000):<br/>    """Trains a model.</span><span id="dc8b" class="mc kz hu ly b fv mh me l mf mg">Args:<br/>      sess: Session.<br/>      data: Features for the training data.<br/>      data_p: Placeholder for the features for the training data.<br/>      labels: Labels for the training data.<br/>      labels_p: Placeholder for the labels for the training data.<br/>      protect: Protected variables.<br/>      protect_p: Placeholder for the protected variables.<br/>      gender_direction: The vector from find_gender_direction().<br/>      pred_learning_rate: Learning rate for predicting labels.<br/>      protect_learning_rate: Learning rate for protecting variables.<br/>      protect_loss_weight: The constant 'alpha' found in<br/>          debias_word_embeddings.ipynb.<br/>      num_steps: Number of training steps.<br/>      batch_size: Number of training examples in each step.<br/>      debug_interval: Frequency at which to log performance metrics during<br/>          training.<br/>    """<br/>    feed_dict = {<br/>        data_p: data,<br/>        labels_p: labels,<br/>        protect_p: protect,<br/>    }<br/>    # define the prediction loss<br/>    pred_loss = tf.losses.mean_squared_error(labels_p, self.pred)</span><span id="a272" class="mc kz hu ly b fv mh me l mf mg"># compute the prediction of the protected variable.<br/>    # The "trainable"/"not trainable" designations are for the predictor. The<br/>    # adversary explicitly specifies its own list of weights to train.<br/>    protect_weights = tf.get_variable(<br/>        "protect_weights", [self.embed_dim, 1], trainable=False)<br/>    protect_pred = tf.matmul(self.pred, protect_weights)<br/>    protect_loss = tf.losses.mean_squared_error(protect_p, protect_pred)</span><span id="a319" class="mc kz hu ly b fv mh me l mf mg">pred_opt = tf.train.AdamOptimizer(pred_learning_rate)<br/>    protect_opt = tf.train.AdamOptimizer(protect_learning_rate)</span><span id="be3a" class="mc kz hu ly b fv mh me l mf mg">protect_grad = {v: g for (g, v) in pred_opt.compute_gradients(protect_loss)}<br/>    pred_grad = []</span><span id="1576" class="mc kz hu ly b fv mh me l mf mg"># applies the gradient expression found in the document linked<br/>    # at the top of this file.<br/>    for (g, v) in pred_opt.compute_gradients(pred_loss):<br/>      unit_protect = tf_normalize(protect_grad[v])<br/>      # the two lines below can be commented out to train without debiasing<br/>      g -= tf.reduce_sum(g * unit_protect) * unit_protect<br/>      g -= protect_loss_weight * protect_grad[v]<br/>      pred_grad.append((g, v))<br/>      pred_min = pred_opt.apply_gradients(pred_grad)</span><span id="3d4f" class="mc kz hu ly b fv mh me l mf mg"># compute the loss of the protected variable prediction.<br/>    protect_min = protect_opt.minimize(protect_loss, var_list=[protect_weights])</span><span id="02e7" class="mc kz hu ly b fv mh me l mf mg">sess.run(tf.global_variables_initializer())<br/>    sess.run(tf.local_variables_initializer())<br/>    step = 0<br/>    while step &lt; num_steps:<br/>      # pick samples at random without replacement as a minibatch<br/>      ids = np.random.choice(len(data), batch_size, False)<br/>      data_s, labels_s, protect_s = data[ids], labels[ids], protect[ids]<br/>      sgd_feed_dict = {<br/>          data_p: data_s,<br/>          labels_p: labels_s,<br/>          protect_p: protect_s,<br/>      }</span><span id="ae8b" class="mc kz hu ly b fv mh me l mf mg">if not step % debug_interval:<br/>        metrics = [pred_loss, protect_loss, self.projection]<br/>        metrics_o = sess.run(metrics, feed_dict=feed_dict)<br/>        pred_loss_o, protect_loss_o, proj_o = metrics_o<br/>        # log stats every so often: number of steps that have passed,<br/>        # prediction loss, adversary loss<br/>        print("step: %d; pred_loss_o: %f; protect_loss_o: %f" % (step,<br/>                     pred_loss_o, protect_loss_o))<br/>        for i in range(proj_o.shape[1]):<br/>          print("proj_o: %f; dot(proj_o, gender_direction): %f)" %<br/>                       (np.linalg.norm(proj_o[:, i]),<br/>                       np.dot(proj_o[:, i].flatten(), gender_direction)))<br/>      sess.run([pred_min, protect_min], feed_dict=sgd_feed_dict)<br/>      step += 1<br/>      <br/>def filter_analogies(analogies,<br/>                     index_map):<br/>  filtered_analogies = []<br/>  for analogy in analogies:<br/>    if filter(index_map.has_key, analogy) != analogy:<br/>      print "at least one word missing for analogy: %s" % analogy<br/>    else:<br/>      filtered_analogies.append(map(index_map.get, analogy))<br/>  return filtered_analogies</span><span id="1bda" class="mc kz hu ly b fv mh me l mf mg">def make_data(<br/>    analogies, embed,<br/>    gender_direction):<br/>  """Preps the training data.</span><span id="7c3d" class="mc kz hu ly b fv mh me l mf mg">Args:<br/>    analogies: a list of analogies<br/>    embed: the embedding matrix from load_vectors<br/>    gender_direction: the gender direction from find_gender_direction</span><span id="4c7c" class="mc kz hu ly b fv mh me l mf mg">Returns:<br/>    Three numpy arrays corresponding respectively to the input, output, and<br/>    protected variables.<br/>  """<br/>  data = []<br/>  labels = []<br/>  protect = []<br/>  for analogy in analogies:<br/>    # the input is just the word embeddings of the first three words<br/>    data.append(embed[analogy[:3]])<br/>    # the output is just the word embeddings of the last word<br/>    labels.append(embed[analogy[3]])<br/>    # the protected variable is the gender component of the output embedding.<br/>    # the extra pair of [] is so that the array has the right shape after<br/>    # it is converted to a numpy array.<br/>    protect.append([np.dot(embed[analogy[3]], gender_direction)])<br/>  # Convert all three to numpy arrays, and return them.<br/>  return tuple(map(np.array, (data, labels, protect))</span></pre><p id="122d" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">å¯¹æŠ—æ–¹æ³•æœ‰åŠ©äºå‡å°‘å•è¯åµŒå…¥ä¸­çš„åå·®ï¼Œå¹¶ä¸”å¯ä»¥å¾ˆå¥½åœ°æ¨å¹¿åˆ°å…¶ä»–é¢†åŸŸå’Œä»»åŠ¡ã€‚é€šè¿‡è¯•å›¾å¯¹å¯¹æ‰‹éšè—å—ä¿æŠ¤å˜é‡ï¼Œæœºå™¨å­¦ä¹ ç³»ç»Ÿå¯ä»¥å‡å°‘ç³»ç»Ÿä¸­éšå«çš„å…³äºå—ä¿æŠ¤å˜é‡çš„æœ‰åè§çš„ä¿¡æ¯é‡ã€‚é™¤äº†ç‰¹å®šçš„æ–¹æ³•ä¹‹å¤–ï¼Œåœ¨è¿™ä¸ªä¸»é¢˜ä¸Šè¿˜æœ‰è®¸å¤šå˜ä½“ï¼Œå¯ä»¥ç”¨æ¥å®ç°ä¸åŒç¨‹åº¦å’Œç±»å‹çš„å»åç½®ã€‚</p><p id="fb67" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">å¸Œæœ›ä½ å–œæ¬¢é˜…è¯»è¿™ä¸ªæ•…äº‹ï¼Œå¹¶å‘ç°å®ƒæ˜¯æœ‰å¸®åŠ©çš„ã€‚è°¢è°¢ä½ ã€‚</p></div></div>    
</body>
</html>