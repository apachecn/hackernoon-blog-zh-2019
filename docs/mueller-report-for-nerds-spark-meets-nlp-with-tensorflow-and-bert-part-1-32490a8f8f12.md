# ä¹¦å‘†å­çš„ç©†å‹’æŠ¥å‘Šï¼Spark ä¸ TensorFlow å’Œ BERT ç›¸é‡ NLP(ç¬¬ 1 éƒ¨åˆ†)

> åŸæ–‡ï¼š<https://medium.com/hackernoon/mueller-report-for-nerds-spark-meets-nlp-with-tensorflow-and-bert-part-1-32490a8f8f12>

# Apache Spark å®ç° NLP çš„æ­£ç¡®æ–¹æ³•

![](img/b2c77edeea09bdbb787f3b2c18885778.png)

Photo by [Michael](https://unsplash.com/photos/9wXvgLMDetA?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/search/photos/department-of-justice?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)

ä½ æœ‰æ²¡æœ‰æƒ³è¿‡ï¼Œå¦‚æœä½ ä¸è¯»è¿™æœ¬ä¹¦ï¼Œä½ èƒ½è¯´å‡ºä¹¦é‡Œçš„å†…å®¹ï¼Ÿå¦‚æœä½ èƒ½ç”»ä¸€å¼ æ‰€æœ‰é‡è¦äººç‰©ã€åœ°ç‚¹ã€äº‹ä»¶ä»¥åŠå®ƒä»¬ä¹‹é—´å…³ç³»çš„åœ°å›¾ä¼šæ€ä¹ˆæ ·ï¼Ÿè¿™å°±æ˜¯**è‡ªç„¶è¯­è¨€å¤„ç†** (NLP)å’Œ**æ–‡æœ¬æŒ–æ˜**æŠ€æœ¯å¯ä»¥å¸®åŠ©æˆ‘ä»¬ä»¥ä¸€ç§æ–°çš„å’Œä¸åŒçš„æ–¹å¼ç†è§£è‡ªç„¶è¯­è¨€æ•°æ®çš„åœ°æ–¹ã€‚

å¥½å§ï¼ä¹Ÿè®¸â€œé˜…è¯»ä¸€æœ¬ä¹¦â€ä¸æ˜¯ä¸€ä¸ªå¥½çš„ä¾‹å­ï¼Œå› ä¸ºæ¯ä¸ªäºº**æ¯ä¸ªæœˆè‡³å°‘åº”è¯¥é˜…è¯»ä¸¤åˆ°å››æœ¬ä¹¦ï¼**

> *è¿™æ˜¯ä¸€ç³»åˆ—æ–‡ç« ï¼Œé€šè¿‡ä½¿ç”¨åŸºäº Apache Spark æ„å»ºçš„*[*Spark NLP*](https://github.com/JohnSnowLabs/spark-nlp)*åº“å’Œç”± TensorFlow å’Œ BERT æ”¯æŒçš„é¢„è®­ç»ƒæ¨¡å‹æ¥æ¢ç´¢â€œç©†å‹’æŠ¥å‘Šâ€ã€‚*
> 
> è¿™äº›æ–‡ç« å¯¹äºé‚£äº›æœ‰å…´è¶£å­¦ä¹ å¦‚ä½•ä½¿ç”¨ Apache Spark è¿›è¡Œ NLP çš„äººæ¥è¯´æ˜¯çº¯æ•™è‚²æ€§çš„ã€‚

F **ç¬¬ä¸€éƒ¨åˆ†:**é€šè¿‡ä½¿ç”¨ Spark NLP æä¾›çš„é¢„è®­ç»ƒç®¡é“å’Œæ¨¡å‹ï¼Œæ‰§è¡Œ NLP ä»»åŠ¡å¹¶æ³¨é‡Šâ€œ **Mueller æŠ¥å‘Šâ€**ã€‚

Sç¬¬äºŒéƒ¨åˆ† *:* ä½¿ç”¨ BERT è®­ç»ƒçš„æ¨¡å‹ï¼Œåœ¨ Spark NLP ä¸­è®­ç»ƒä¸€ä¸ª POS æ ‡è®°å™¨æ¨¡å‹ï¼Œæ•°æ®æ¸…æ´—ï¼Œé€šè¿‡ POS å’Œ NER åˆ†å—æå–å…³é”®è¯/çŸ­è¯­ã€‚

TT**ç¬¬ä¸‰éƒ¨åˆ†: [GraphFrames](https://github.com/graphframes/graphframes) çš„**å›¾å½¢ç®—æ³•ï¼ŒSpark ML çš„èšç±»å’Œä¸»é¢˜å»ºæ¨¡ï¼Œä»¥åŠ [Gephi](https://gephi.org/) çš„ç½‘ç»œå¯è§†åŒ–ã€‚

![](img/90d61ed09790b3b4150d70aca385e199.png)![](img/5617cba52e3fc92ba003ccae3a7874b6.png)![](img/ef2c14dcce42c7697039f553c8defb46.png)![](img/4601190d4aaaa45409991d7128a2bbba.png)![](img/02d880408f5ecbb6a588c5bf349e4c2d.png)

Extracting keywords from the Mueller Report by using Spark NLP

# å…³äºä¿„ç½—æ–¯å¹²æ¶‰ 2016 å¹´æ€»ç»Ÿé€‰ä¸¾çš„è°ƒæŸ¥æŠ¥å‘Š

**ç±³å‹’æŠ¥å‘Šä¿—ç§°**

![](img/8f53d03a8ad6ffe3a2b50395891bf5c3.png)

Robert Mueller, 2012

æœ€åˆçš„æŠ¥å‘Šæ˜¯ç”±ç¾å›½å‘å¸ƒçš„ã€‚å¸æ³•éƒ¨([åŸå§‹æ–‡ä»¶](https://www.justice.gov/storage/report.pdf))å¯¹äºæˆ‘ä»¬è¿™äº›ä¸ç†Ÿæ‚‰ä»–çš„è°ƒæŸ¥çš„äººæ¥è¯´:

> ç»è¿‡å¤šå¹´çš„è°ƒæŸ¥ï¼Œå¸æ³•éƒ¨å‘¨å››å…¬å¸ƒäº†ç‰¹åˆ«é¡¾é—®ç½—ä¼¯ç‰¹Â·ç©†å‹’æŠ¥å‘Šçš„ç¼–è¾‘å‰¯æœ¬ã€‚è¿™ä»½æŠ¥å‘Šå°†è¿‘ **400** é¡µï¼Œæ¶µç›–äº†ä»**ä¿„ç½—æ–¯**å¹²æ¶‰ 2016 **ç¾å›½æ€»ç»Ÿé€‰ä¸¾**åˆ°**å”çº³å¾·Â·å·æ™®**æ€»ç»Ÿæ˜¯å¦å¦¨ç¢å¸æ³•å…¬æ­£ç­‰é—®é¢˜ã€‚[åˆ†è¯å™¨](https://medium.com/u/374a801b3eb2#tokenizer)
> 
> *   [è§„æ ¼åŒ–å™¨](https://nlp.johnsnowlabs.com/docs/en/annotators#normalizer)*   [æ–¯ç‰¹æ¢…å°”](https://nlp.johnsnowlabs.com/docs/en/annotators#stemmer)*   [Lemmatizer](https://nlp.johnsnowlabs.com/docs/en/annotators#lemmatizer)*   [æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…å™¨](https://nlp.johnsnowlabs.com/docs/en/annotators#regexmatcher)*   [æ–‡æœ¬åŒ¹é…å™¨](https://nlp.johnsnowlabs.com/docs/en/annotators#textmatcher)*   [åˆ‡é¥¼æœº](https://nlp.johnsnowlabs.com/docs/en/annotators#chunker)*   [çº¦ä¼šå¯¹è±¡](https://nlp.johnsnowlabs.com/docs/en/annotators#datematcher)*   [sentenced æ£€æµ‹å™¨](https://nlp.johnsnowlabs.com/docs/en/annotators#sentencedetector)*   [æ·±åº¦æ£€æµ‹å™¨](https://nlp.johnsnowlabs.com/docs/en/annotators#deepsentencedetector)*   [åç½®æ ‡è®°](https://nlp.johnsnowlabs.com/docs/en/annotators#postagger)*   [viveksentimentdetector](https://nlp.johnsnowlabs.com/docs/en/annotators#viveknsentimentdetector)*   [æƒ…æ„Ÿæ¢æµ‹å™¨:æƒ…æ„Ÿåˆ†æ](https://nlp.johnsnowlabs.com/docs/en/annotators#sentimentdetector)*   [è¯è¯­åµŒå…¥](https://nlp.johnsnowlabs.com/docs/en/annotators#word-embeddings)*   [NER CRF](https://nlp.johnsnowlabs.com/docs/en/annotators#ner-crf)*   [NER DL](https://nlp.johnsnowlabs.com/docs/en/annotators#ner-dl)*   [è¯ºç»´æ ¼æ‹¼å†™æ£€æŸ¥å™¨](https://nlp.johnsnowlabs.com/docs/en/annotators#norvig-spellchecker)*   [å¯¹ç§°æ‹¼å†™æ£€æŸ¥å™¨](https://nlp.johnsnowlabs.com/docs/en/annotators#symmetric-spellchecker)*   [ä¾èµ–è§£æå™¨](https://nlp.johnsnowlabs.com/docs/en/annotators#dependency-parser)*   [ç±»å‹ä¾èµ–è§£æå™¨](https://nlp.johnsnowlabs.com/docs/en/annotators#typed-dependency-parser)
> 
> å…³äºæ³¨é‡Šå™¨ã€æ¨¡å‹å’Œç®¡é“çš„å®Œæ•´åˆ—è¡¨ï¼Œæ‚¨å¯ä»¥é˜…è¯»[ä»–ä»¬çš„åœ¨çº¿æ–‡æ¡£](https://nlp.johnsnowlabs.com/docs/en/annotators)ã€‚
> 
> > å®Œå…¨æŠ«éœ²:æˆ‘æ˜¯[æŠ•ç¨¿äºº](https://github.com/JohnSnowLabs/spark-nlp/graphs/contributors)ä¹‹ä¸€ï¼
> 
> # å®‰è£… Spark NLP
> 
> æˆ‘çš„ç¯å¢ƒ:
> 
> *   [ç«èŠ± NLP](https://github.com/JohnSnowLabs/spark-nlp) 2.0.3 å‘å¸ƒ
> *   é˜¿å¸•å¥‡ç«èŠ± 2.4.1
> *   é˜¿å¸•å¥‡é½æŸæ—é£è‰‡ç‰ˆæœ¬ 0.8.2
> *   ä½¿ç”¨ MacBook Pro/macOS è¿›è¡Œæœ¬åœ°è®¾ç½®
> *   ä½¿ç”¨ 40 å°æœåŠ¡å™¨çš„ Cloudera/CDH 6.2 é›†ç¾¤è®¾ç½®
> *   ç¼–ç¨‹è¯­è¨€:Scala(ä½†æ˜¯ä¸ç”¨æ‹…å¿ƒï¼ŒSpark å’Œ Spark NLP ä¸­çš„ Python APIs ä¸ Scala è¯­è¨€éå¸¸ç›¸ä¼¼)
> 
> æˆ‘å°†è§£é‡Šå¦‚ä½•ä¸ºæˆ‘çš„ç¯å¢ƒè®¾ç½® Spark NLPã€‚å°½ç®¡å¦‚æ­¤ï¼Œå¦‚æœæ‚¨å¸Œæœ›å°è¯•ä¸€äº›ä¸åŒçš„ä¸œè¥¿ï¼Œæ‚¨å¯ä»¥é€šè¿‡è®¿é—®ä¸»è¦çš„å…¬å…±å­˜å‚¨åº“æˆ–æŸ¥çœ‹åŒ…å«å¤§é‡ç¤ºä¾‹çš„ showcase å­˜å‚¨åº“æ¥äº†è§£æœ‰å…³å¦‚ä½•ä½¿ç”¨ Spark NLP çš„æ›´å¤šä¿¡æ¯:
> 
> **ä¸»**å…¬å…±çŸ¥è¯†åº“:
> 
> [](https://github.com/johnsnowlabs/spark-nlp) [## çº¦ç¿°Â·æ–¯è¯ºå®éªŒå®¤/spark-nlp
> 
> ### Apache Spark è‡ªç„¶è¯­è¨€ç†è§£åº“ã€‚çº¦ç¿°Â·æ–¯è¯ºå®éªŒå®¤/spark-nlp
> 
> github.com](https://github.com/johnsnowlabs/spark-nlp) 
> 
> **å±•æŸœ**å‚¨å­˜åº“:
> 
> [](https://github.com/JohnSnowLabs/spark-nlp-workshop) [## çº¦ç¿°Â·æ–¯è¯ºå®éªŒå®¤/spark-NLP-è½¦é—´
> 
> ### ä¸º Apache Spark ä½¿ç”¨ John Snow Labs çš„ NLP çš„å…¬å…±è¿è¡Œç¤ºä¾‹ã€‚â€” JohnSnowLabs/spark-nlp å·¥ä½œå®¤
> 
> github.com](https://github.com/JohnSnowLabs/spark-nlp-workshop) 
> 
> æˆ‘ä»¬å¼€å§‹å§ï¼è¦åœ¨ Apache Zeppelin ä¸­ä½¿ç”¨ Spark NLPï¼Œæ‚¨æœ‰ä¸¤ç§é€‰æ‹©ã€‚è¦ä¹ˆä½¿ç”¨ **Spark åŒ…**ï¼Œè¦ä¹ˆä½ å¯ä»¥è‡ªå·±æ„å»ºä¸€ä¸ªèƒ–ç½å­ï¼Œå¹¶åœ¨ Spark ä¼šè¯ä¸­å°†å…¶ä½œä¸º**å¤–éƒ¨ç½å­**åŠ è½½ã€‚è¦ä¸æˆ‘ç»™ä½ ä»¬ä¿©çœ‹çœ‹ï¼Ÿ
> 
> ## é¦–å…ˆï¼Œå¸¦ Spark åŒ…:
> 
> è¦ä¹ˆæŠŠè¿™ä¸ªæ·»åŠ åˆ°ä½ çš„ **conf/zeppelin-env.sh**
> 
> ```
> *# set options to pass spark-submit command*
> export SPARK_SUBMIT_OPTIONS**=**"--packages com.johnsnowlabs.nlp:spark-nlp_2.11:2.0.3"
> ```
> 
> 2.æˆ–è€…ï¼Œå°†å…¶æ·»åŠ åˆ°**é€šç”¨å†…è”é…ç½®è§£é‡Šå™¨**(åœ¨å¼€å§‹ Spark ä¼šè¯ä¹‹å‰ï¼Œåœ¨ç¬”è®°æœ¬çš„å¼€å¤´):
> 
> ```
> %spark.conf# spark.jars.packages can be used for adding packages into spark interpreter
> spark.jars.packages com.johnsnowlabs.nlp:spark-nlp_2.11:2.0.3
> ```
> 
> ## å…¶æ¬¡ï¼ŒåŠ è½½å¤–éƒ¨ JAR:
> 
> è¦å»ºé€ ä¸€ä¸ªå¤§ç½å­ï¼Œä½ éœ€è¦åšçš„å°±æ˜¯:
> 
> ```
> $ git clone [https://github.com/JohnSnowLabs/spark-nlp](https://github.com/JohnSnowLabs/spark-nlp#apache-zeppelin)
> $ cd spark-nlp
> $ sbt assembly
> ```
> 
> ç„¶åï¼Œæ‚¨å¯ä»¥æŒ‰ç…§æˆ‘æåˆ°çš„ä¸¤ç§æ–¹æ³•ä¹‹ä¸€æ¥æ·»åŠ è¿™ä¸ªå¤–éƒ¨ JARã€‚æ‚¨åªéœ€è¦åœ¨ç¬¬ä¸€ä¸ªé€‰é¡¹ä¸­å°†â€œâ€” packagesâ€æ”¹ä¸ºâ€œâ€” jarsâ€ã€‚æˆ–è€…å¯¹äºç¬¬äºŒä¸ªè§£å†³æ–¹æ¡ˆï¼Œåªéœ€è¦â€œspark.jarsâ€ã€‚
> 
> ## ç”¨ Spark NLP å¯åŠ¨ Spark
> 
> ç°åœ¨ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡å¯¼å…¥ Spark NLP æ³¨é‡Šå™¨å¼€å§‹å°† **Spark NLP 2.0.3** ä¸ **Zeppelin 0.8.2** å’Œ **Spark 2.4.1** ä¸€èµ·ä½¿ç”¨:
> 
> ```
> import com.johnsnowlabs.nlp.base._
> import com.johnsnowlabs.nlp.annotator._
> import org.apache.spark.ml.Pipeline
> ```
> 
> Apache Zeppelin å°†å¯åŠ¨ä¸€ä¸ªæ–°çš„ Spark ä¼šè¯ï¼Œå®ƒä¸ Spark NLP ä¸€èµ·æä¾›ï¼Œä¸ç®¡æ‚¨ä½¿ç”¨çš„æ˜¯ Spark åŒ…è¿˜æ˜¯å¤–éƒ¨ JARã€‚
> 
> ## é˜…è¯»ç©†å‹’æŠ¥å‘Š PDF æ–‡ä»¶
> 
> è¿˜è®°å¾—å…³äº PDF æ–‡ä»¶ä¸æ˜¯çœŸæ­£çš„ PDF çš„é—®é¢˜å—ï¼Ÿæˆ‘ä»¬æœ‰ä¸‰ä¸ªé€‰æ‹©:
> 
> 1.  æ‚¨å¯ä»¥ä½¿ç”¨ä»»ä½•æ‚¨å–œæ¬¢çš„ OCR å·¥å…·/åº“æ¥ç”Ÿæˆ PDF æˆ–æ–‡æœ¬æ–‡ä»¶ã€‚
> 2.  æˆ–è€…æ‚¨å¯ä»¥ä½¿ç”¨ç¤¾åŒºåˆ›å»ºçš„å·²ç»å¯æœç´¢å’Œå¯é€‰æ‹©çš„ PDF æ–‡ä»¶ã€‚
> 3.  æˆ–è€…ä½ å¯ä»¥ç›´æ¥ç”¨ Spark NLPï¼
> 
> Spark NLP å¸¦æœ‰ä¸€ä¸ª **OCR** åŒ…ï¼Œå¯ä»¥è¯»å– PDF æ–‡ä»¶å’Œæ‰«æå›¾åƒã€‚ä½†æ˜¯ï¼Œæˆ‘æŠŠé€‰é¡¹ 2 å’Œé€‰é¡¹ 3 æ··åœ¨äº†ä¸€èµ·ã€‚(æˆ‘éœ€è¦åœ¨æ•´ä¸ªé›†ç¾¤ä¸Šä¸ºåŸºäºå›¾åƒçš„ OCR å®‰è£… Tesseract 4.x+,æ‰€ä»¥æˆ‘æœ‰ç‚¹æ‡’)
> 
> æ‚¨å¯ä»¥ä» Scribd ä¸‹è½½è¿™ä¸¤ä¸ª PDF æ–‡ä»¶:
> 
> *   [ç©†å‹’æŠ¥å‘Šç¼–è¾‘ç¬¬ä¸€å·](https://www.scribd.com/document/406904220/Word-searchable-Mueller-Report-Redacted-Vol-I)
> *   [ç©†å‹’æŠ¥å‘Šä¿®è®¢ç¬¬äºŒå·](https://www.scribd.com/document/406904826/Word-searchable-Mueller-Report-Redacted-Vol-II)
> 
> å½“ç„¶ä½ ä¹Ÿå¯ä»¥ç›´æ¥ä¸‹è½½æ–‡å­—ç‰ˆï¼Œç”¨ Spark çœ‹ã€‚ä½†æ˜¯ï¼Œæˆ‘æƒ³å‘æ‚¨å±•ç¤ºå¦‚ä½•ä½¿ç”¨ Spark NLP é™„å¸¦çš„ OCRã€‚
> 
> **Spark NLP OCR:**
> 
> è®©æˆ‘ä»¬ä¸ºä¸ OCR ç›¸å…³çš„ä¸€åˆ‡åˆ›å»ºä¸€ä¸ªåŠ©æ‰‹å‡½æ•°:
> 
> ```
> import com.johnsnowlabs.nlp.util.io.OcrHelper
> val ocrHelper = new OcrHelper()
> ```
> 
> ç°åœ¨ï¼Œæˆ‘ä»¬éœ€è¦é˜…è¯» PDF å¹¶æ ¹æ®å…¶å†…å®¹åˆ›å»ºä¸€ä¸ªæ•°æ®é›†ã€‚Spark NLP ä¸­çš„ OCR æ¯é¡µåˆ›å»ºä¸€è¡Œ:
> 
> ```
> //If you do this locally you can use **file:///** or **hdfs:///** if the files are hosted in Hadoop**val muellerFirstVol = ocrHelper.createDataset**(spark, "/tmp/Mueller/Mueller-Report-Redacted-Vol-I-Released-04.18.2019-Word-Searchable.-Reduced-Size.pdf")
> ```
> 
> ![](img/ab3ad912c74f77504ef8cfc019a4b2ac.png)
> 
> DataFrame created by reading the PDF file
> 
> å¦‚æ‚¨æ‰€è§ï¼Œæˆ‘æ­£åœ¨å°†è¯¥æŠ¥å‘Šçš„â€œç¬¬ä¸€å·â€ä»¥ PDF æ ¼å¼åŠ è½½åˆ°ä¸€ä¸ªæ•°æ®é›†ä¸­ã€‚æˆ‘åœ¨æœ¬åœ°è¿™æ ·åšåªæ˜¯ä¸ºäº†è¯´æ˜ä½¿ç”¨ Apache Spark å’Œ Spark NLP å¹¶ä¸æ€»æ˜¯éœ€è¦é›†ç¾¤ï¼
> 
> **æç¤º 1** :å¦‚æœ PDF å®é™…ä¸Šæ˜¯æ‰«æå›¾åƒï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨è¿™äº›è®¾ç½®(ä½†åœ¨æˆ‘ä»¬çš„ç”¨ä¾‹ä¸­ï¼Œæˆ‘ä»¬å‘ç°äº†ä¸€ä¸ªå¯é€‰çš„ PDF):
> 
> ```
> ocrHelper.setPreferredMethod("image")
> ocrHelper.setFallbackMethod(false)
> ocrHelper.setMinSizeBeforeFallback(0)
> ```
> 
> **æç¤º 2** :å¦‚æœéœ€è¦ï¼Œæ‚¨å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼å°† Spark æ•°æ®é›†è½¬æ¢ä¸º DataFrame:
> 
> ```
> **muellerFirstVol.toDF()**
> ```
> 
> # Spark NLP ç®¡é“å’Œæ¨¡å‹
> 
> ## æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ çš„è‡ªç„¶è¯­è¨€å¤„ç†
> 
> ç°åœ¨æ˜¯æ—¶å€™åšä¸€äº› NLP ä»»åŠ¡äº†ã€‚æ­£å¦‚æˆ‘åœ¨å¼€å§‹æ—¶æåˆ°çš„ï¼Œæˆ‘ä»¬å¸Œæœ›ä½¿ç”¨å·²ç»é¢„å…ˆåŸ¹è®­å¥½çš„ç”± Spark NLP åœ¨ç¬¬ä¸€éƒ¨åˆ†ä¸­æä¾›çš„**ç®¡é“**å’Œ**å‹å·**ã€‚è¿™äº›æ˜¯ä¸€äº›å¯ç”¨çš„[ç®¡é“](https://nlp.johnsnowlabs.com/docs/en/pipelines)å’Œ[å‹å·](https://nlp.johnsnowlabs.com/docs/en/models):
> 
> ![](img/0dc4f488479be8907fdbb50b7f840740.png)
> 
> Spark NLP pre-trained Pipelines and Models (full list of [pipelines](https://nlp.johnsnowlabs.com/docs/en/pipelines) and [models](https://nlp.johnsnowlabs.com/docs/en/models))
> 
> ä¸è¿‡ï¼Œæˆ‘æƒ³å…ˆç”¨ä¸€ä¸ªåä¸º**â€œexplain _ document _ dlâ€**çš„ç®¡é“ã€‚è®©æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•ä¸‹è½½è¿™ä¸ªç®¡é“ï¼Œç”¨å®ƒæ¥æ³¨é‡Šä¸€äº›è¾“å…¥ï¼Œä»¥åŠå®ƒåˆ°åº•æä¾›äº†ä»€ä¹ˆ:
> 
> ```
> import com.johnsnowlabs.nlp.pretrained.PretrainedPipelineval pipeline = PretrainedPipeline("**explain_document_dl**", "**en**")// This DataFrame has one sentence for testing
> val testData = Seq(
>     "Donald Trump is the 45th President of the United States"
>     ).toDS.toDF("text")// Let's use our pre-trained pipeline to predict the test dataset
> pipeline.transform(testData).show
> ```
> 
> ä»¥ä¸‹æ˜¯çš„ç»“æœã€‚æ˜¾ç¤º():
> 
> ![](img/79d84565edfd1f9b8180bfc61e8fd1bc.png)
> 
> Spark NLP pre-trained â€œ**explain_document_dl**â€ pipeline
> 
> æˆ‘çŸ¥é“ï¼è¿™æ¡ç®¡é“é‡Œæœ‰å¾ˆå¤šä¸œè¥¿ã€‚è®©æˆ‘ä»¬ä»æˆ‘ä»¬åœ¨**â€œexplain _ document _ dlâ€**ç®¡é“ä¸­çš„ NLP æ³¨é‡Šå™¨å¼€å§‹:
> 
> *   æ–‡ä»¶æ±‡ç¼–å‘˜
> *   åˆ¤åˆ‘æ£€æµ‹å‘˜
> *   æ ‡è®°å™¨
> *   å¼•ç†æ¨¡å‹
> *   æ–¯ç‰¹æ¢…å°”
> *   æ„ŸçŸ¥å™¨æ¨¡å‹
> *   ContextSpellCheckerModel
> *   WordEmbeddings(æ‰‹å¥— 6B 100)
> *   NerDLModel
> *   NerConverter(åˆ†å—)
> 
> æ®æˆ‘æ‰€çŸ¥ï¼Œè¿™ä¸ªç®¡é“ä¸­æœ‰ä¸€äº›æ ‡æ³¨å™¨æ­£åœ¨ä½¿ç”¨ç”± **TensorFlow** é©±åŠ¨çš„**æ·±åº¦å­¦ä¹ **è¿›è¡Œç›‘ç£å­¦ä¹ ã€‚ä¾‹å¦‚ï¼Œå½“æ‚¨åŠ è½½æ­¤ç®¡é“æ—¶ï¼Œæ‚¨ä¼šæ³¨æ„åˆ°è¿™å‡ è¡Œ:
> 
> ```
> pipeline: com.johnsnowlabs.nlp.pretrained.PretrainedPipeline = PretrainedPipeline(**explain_document_dl**,en,public/models)adding (ner-dl/mac/_sparse_feature_cross_op.so,ner-dl/mac/_lstm_ops.so)loading to **tensorflow**
> ```
> 
> ä¸ºç®€å•èµ·è§ï¼Œæˆ‘å°†åˆ†åˆ«é€‰æ‹©ä¸€ç»„åˆ—ï¼Œè¿™æ ·æˆ‘ä»¬å°±å¯ä»¥å®é™…çœ‹åˆ°ä¸€äº›ç»“æœ:
> 
> ![](img/b2bfe30084e6056f5936085588de5e70.png)
> 
> Spark NLP pre-trained â€œ**explain_document_dl**â€ pipeline
> 
> è¿™æ˜¯ä¸€ä¸ªéå¸¸å®Œæ•´çš„ NLP ç®¡é“ã€‚åƒå…¶ä»– NLP åº“ä¸€æ ·ï¼Œå®ƒæœ‰è®¸å¤š NLP ä»»åŠ¡ï¼Œç”šè‡³æ›´åƒ**æ‹¼å†™æ£€æŸ¥ã€‚**ä½†æ˜¯ï¼Œå¦‚æœä½ åªæ˜¯åœ¨å¯»æ‰¾ä¸€ä¸ªæˆ–ä¸¤ä¸ªè‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ï¼Œå¦‚ POS æˆ– NERï¼Œè¿™å¯èƒ½æœ‰ç‚¹é‡ã€‚
> 
> è®©æˆ‘ä»¬å°è¯•å¦ä¸€ä¸ªé¢„å…ˆè®­ç»ƒå¥½çš„ç®¡é“ï¼Œåä¸º**â€œentity _ recognizer _ dlâ€:**
> 
> ```
> import com.johnsnowlabs.nlp.pretrained.PretrainedPipelineval pipeline = PretrainedPipeline("**entity_recognizer_dl**", "**en**")val testData = Seq(
>     "Donald Trump is the 45th President of the United States"    ).toDS.toDF("text")// Let's use our pre-trained pipeline to predict the test dataset
> pipeline.transform(testData).show
> ```
> 
> å¦‚æ‚¨æ‰€è§ï¼Œä½¿ç”¨é¢„å…ˆè®­ç»ƒçš„ç®¡é“éå¸¸å®¹æ˜“ã€‚ä½ åªéœ€è¦æ”¹å˜å®ƒçš„åå­—ï¼Œå®ƒå°±ä¼šä¸‹è½½å¹¶ç¼“å­˜åœ¨æœ¬åœ°ã€‚è¿™æ¡ç®¡é“é‡Œæœ‰ä»€ä¹ˆï¼Ÿ
> 
> *   æ–‡ä»¶
> *   å¥å­
> *   ä»£å¸
> *   **åµŒå…¥**
> *   **NER**
> *   **NER å¤§å—**
> 
> è®©æˆ‘ä»¬æ¥çœ‹çœ‹ NER æ¨¡å¼åœ¨è¿™ä¸¤æ¡ç®¡é“ä¸­å‘ç”Ÿäº†ä»€ä¹ˆã€‚**å‘½åå®ä½“è¯†åˆ«(NER)** ä½¿ç”¨**å•è¯åµŒå…¥** ( **æ‰‹å¥—**æˆ–**ä¼¯ç‰¹**)è¿›è¡Œè®­ç»ƒã€‚æˆ‘å¯ä»¥å¼•ç”¨è¯¥é¡¹ç›®çš„ä¸»è¦ç»´æŠ¤è€…ä¹‹ä¸€çš„è¯æ¥è¯´æ˜å®ƒæ˜¯ä»€ä¹ˆ:
> 
> > NerDLModel æ˜¯ä¸€ä¸ªè®­ç»ƒè¿‡ç¨‹çš„ç»“æœï¼Œç”± NerDLApproach SparkML estimator å‘èµ·ã€‚è¿™ä¸ªä¼°ç®—å™¨æ˜¯ä¸€ä¸ªå¼ é‡æµ DLmodelã€‚å®ƒéµå¾ªå…·æœ‰å·ç§¯ç¥ç»ç½‘ç»œçš„åŒ LSTM æ–¹æ¡ˆï¼Œåˆ©ç”¨å•è¯åµŒå…¥è¿›è¡Œä»¤ç‰Œå’Œå­ä»¤ç‰Œåˆ†æã€‚
> 
> ä½ å¯ä»¥é˜…è¯»è¿™ç¯‡å…³äºä½¿ç”¨**å¼ é‡æµ**å›¾ä»¥åŠ Spark NLP å¦‚ä½•ä½¿ç”¨å®ƒæ¥è®­ç»ƒå…¶ NER æ¨¡å‹çš„å®Œæ•´æ–‡ç« :
> 
> [](/@saif1988/spark-nlp-walkthrough-powered-by-tensorflow-9965538663fd) [## Spark NLP æ¼”ç»ƒï¼Œç”± TensorFlow æä¾›æ”¯æŒ
> 
> ### æœ¬æ–‡æ˜¯ä¸€ä¸ªæ¼”ç»ƒè§£å†³ä¸€ä¸ªç°å®çš„ç”¨ä¾‹è‡ªç„¶è¯­è¨€ç†è§£åœ¨åŒ»ç–—ä¿å¥ä½¿ç”¨â€¦
> 
> medium.com](/@saif1988/spark-nlp-walkthrough-powered-by-tensorflow-9965538663fd) 
> 
> å›åˆ°æˆ‘ä»¬çš„ç®¡é“ï¼ŒNER å—å°†æå–å‘½åå®ä½“å—ã€‚ä¾‹å¦‚ï¼Œå¦‚æœä½ æœ‰**å”çº³å¾·** - >ä¼Šä½©å°”å’Œ**å·æ™®** - >ä¼Šä½©å°”ï¼Œå°±ä¼šäº§ç”Ÿ**å§œæ‡¿ç¿”å·æ™®**ã€‚çœ‹ä¸€ä¸‹è¿™ä¸ªä¾‹å­:
> 
> ![](img/99cbeb4b2fc4e0899eacfb0d897c0842.png)
> 
> Spark NLP pre-trained â€œ**entity_recognizer_dl**â€ pipeline
> 
> ## è‡ªå®šä¹‰ç®¡é“
> 
> å°±ä¸ªäººè€Œè¨€ï¼Œå½“æˆ‘å¤„ç†é¢„å…ˆè®­ç»ƒå¥½çš„æ¨¡å‹æ—¶ï¼Œæˆ‘æ›´å–œæ¬¢æ„å»ºè‡ªå·±çš„ NLP ç®¡é“ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæˆ‘å¯ä»¥å®Œå…¨æ§åˆ¶æˆ‘æƒ³è¦ä½¿ç”¨ä»€ä¹ˆç±»å‹çš„æ³¨é‡Šå™¨ï¼Œæˆ‘æƒ³è¦ ML è¿˜æ˜¯ DL æ¨¡å‹ï¼Œåœ¨æ··åˆä¸­ä½¿ç”¨æˆ‘è‡ªå·±è®­ç»ƒçš„æ¨¡å‹ï¼Œå®šåˆ¶æ¯ä¸ªæ³¨é‡Šå™¨çš„è¾“å…¥/è¾“å‡ºï¼Œé›†æˆ Spark ML å‡½æ•°ï¼Œç­‰ç­‰ï¼
> 
> > æ˜¯å¦æœ‰å¯èƒ½åˆ›å»ºè‡ªå·±çš„ NLP ç®¡é“ï¼Œä½†ä»ç„¶åˆ©ç”¨é¢„å…ˆè®­ç»ƒçš„æ¨¡å‹ï¼Ÿ
> 
> ç­”æ¡ˆæ˜¯**æ˜¯çš„**ï¼è®©æˆ‘ä»¬çœ‹ä¸€ä¸ªä¾‹å­:
> 
> ```
> val document = new DocumentAssembler()
>   .setInputCol("text")
>   .setOutputCol("document")val sentence = new SentenceDetector()
>   .setInputCols(Array("document"))
>   .setOutputCol("sentence")
>   .setExplodeSentences(true)val token = new Tokenizer()
>   .setInputCols(Array("document"))
>   .setOutputCol("token")val normalized = new Normalizer()
>   .setInputCols(Array("token"))
>   .setOutputCol("normalized")val pos = PerceptronModel.pretrained()
>     .setInputCols("sentence", "normalized")
>     .setOutputCol("pos")val chunker = new Chunker()
>   .setInputCols(Array("document", "pos"))
>   .setOutputCol("pos_chunked")
>   .setRegexParsers(Array(
>       "<DT>?<JJ>*<NN>"
>     ))val embeddings = WordEmbeddingsModel.pretrained()
>     .setOutputCol("embeddings")val ner = NerDLModel.pretrained()
>     .setInputCols("document", "normalized", "embeddings")
>     .setOutputCol("ner")val nerConverter = new NerConverter()
>     .setInputCols("document", "token", "ner")
>     .setOutputCol("ner_chunked")val pipeline = new Pipeline().setStages(Array(
>       document, 
>       sentence,
>       token, 
>       normalized,
>       pos,
>       chunker,
>       embeddings,
>       ner,
>       nerConverter   
> ))
> ```
> 
> å°±æ˜¯è¿™æ ·ï¼ç›¸å½“ç®€å•å’Œæ´»æ³¼ã€‚é‡è¦çš„æ˜¯ï¼Œæ‚¨å¯ä»¥ä¸ºæ¯ä¸ªæ³¨é‡Šå™¨è®¾ç½®æƒ³è¦çš„è¾“å…¥ã€‚ä¾‹å¦‚ï¼Œå¯¹äºè¯æ€§æ ‡æ³¨ï¼Œæˆ‘å¯ä»¥ä½¿ç”¨æ ‡è®°ã€è¯å¹²æ ‡è®°ã€è¯æ±‡åŒ–æ ‡è®°æˆ–è§„èŒƒåŒ–æ ‡è®°ã€‚è¿™å¯èƒ½ä¼šæ”¹å˜æ³¨é‡Šå™¨çš„ç»“æœã€‚NerDLModel ä¹Ÿä¸€æ ·ã€‚æˆ‘ä¸º POS å’Œ Ner æ¨¡å‹éƒ½é€‰æ‹©äº†è§„èŒƒåŒ–çš„ä»¤ç‰Œï¼Œå› ä¸ºæˆ‘çŒœæˆ‘çš„æ•°æ®é›†æœ‰ç‚¹ä¹±ï¼Œéœ€è¦æ¸…ç†ä¸€ä¸‹ã€‚
> 
> è®©æˆ‘ä»¬ä½¿ç”¨æˆ‘ä»¬å®šåˆ¶çš„ç®¡é“ã€‚å¦‚æœä½ äº†è§£ Spark ML ç®¡é“ï¼Œå®ƒæœ‰ä¸¤ä¸ªé˜¶æ®µã€‚ä¸€ä¸ªæ˜¯æ‹Ÿåˆï¼Œå³åœ¨ç®¡é“å†…è®­ç»ƒæ¨¡å‹ã€‚ç¬¬äºŒæ˜¯é€šè¿‡å°†æ•°æ®è½¬æ¢æˆæ–°çš„æ•°æ®æ¡†æ¶æ¥é¢„æµ‹æ–°æ•°æ®ã€‚
> 
> ```
> val nlpPipelineModel = pipeline.**fit**(**muellerFirstVol**)val nlpPipelinePrediction = nlpPipelineModel.**transform**(**muellerFirstVol**)
> ```
> 
> çš„ã€‚fit()åœ¨è¿™é‡Œæ˜¯ç”¨æ¥è£…é¥°çš„ï¼Œå› ä¸ºæ‰€æœ‰çš„ä¸œè¥¿éƒ½æ˜¯é¢„å…ˆè®­ç»ƒå¥½çš„ã€‚æˆ‘ä»¬ä¸éœ€è¦è®­ç»ƒä»»ä½•ä¸œè¥¿ã€‚transform()æ˜¯æˆ‘ä»¬ä½¿ç”¨ç®¡é“ä¸­çš„æ¨¡å‹æ¥åˆ›å»ºä¸€ä¸ªåŒ…å«æ‰€æœ‰é¢„æµ‹çš„æ–°æ•°æ®æ¡†æ¶çš„åœ°æ–¹ã€‚ä½†æ˜¯å¦‚æœæˆ‘ä»¬æœ‰è‡ªå·±çš„æ¨¡å‹æˆ–è€… Spark ML å‡½æ•°éœ€è¦è®­ç»ƒï¼Œé‚£ä¹ˆã€‚fit()éœ€è¦ä¸€äº›æ—¶é—´æ¥è®­ç»ƒæ¨¡å‹ã€‚
> 
> åœ¨æœ¬åœ°æœºå™¨ä¸Šï¼Œè¿™éœ€è¦å¤§çº¦ 3 ç§’é’Ÿæ¥è¿è¡Œã€‚æˆ‘çš„ç¬”è®°æœ¬ç”µè„‘æœ‰é…·ç¿ i9ã€32G å†…å­˜å’Œ Vega 20(å¦‚æœè¿™å¾ˆé‡è¦çš„è¯)ï¼Œæ‰€ä»¥å®ƒæ˜¯ä¸€å°ç›¸å½“ä¸é”™çš„æœºå™¨ã€‚
> 
> ![](img/1f572c3ef385aa300c74d9523c822d2a.png)
> 
> Apache Spark on Local machine
> 
> è¿™ä¸ªä¾‹å­ä¸å¤§æ•°æ®åœºæ™¯å®Œå…¨ä¸åŒï¼Œåœ¨å¤§æ•°æ®åœºæ™¯ä¸­ï¼Œæ‚¨éœ€è¦å¤„ç†æ•°ç™¾ä¸‡æ¡è®°å½•ã€å¥å­æˆ–å•è¯ã€‚å…¶å®è¿å°æ•°æ®éƒ½ç®—ä¸ä¸Šã€‚ç„¶è€Œï¼Œæˆ‘ä»¬ä½¿ç”¨ Apache Spark æ˜¯æœ‰åŸå› çš„ï¼è®©æˆ‘ä»¬åœ¨ä¸€ä¸ªå¯ä»¥åˆ†é…ä»»åŠ¡çš„é›†ç¾¤ä¸­è¿è¡Œå®ƒã€‚
> 
> ä¾‹å¦‚ï¼Œä¸ä¹…å‰æˆ‘æœ‰ä¸€ä¸ªæ›´å¤§æ›´å¤æ‚çš„ Spark NLP ç®¡é“æ¥å¤„ç†æ•´ä¸ªæ³•å›½å¤§è¾©è®ºï¼Œå®ƒè¢«ç§°ä¸ºâ€œ[**Le Grand dÃ©bat Nationale**](https://granddebat.fr/)â€ã€‚
> 
> ![](img/088c577dc1c52034cae0362342d219ab.png)![](img/cb83b9cf428854058467edf9b6fd2257.png)![](img/6b66627ea01b3a0fe3b061cc716fdfdf.png)![](img/9593777da414c43f857ecac61f8fd2ee.png)![](img/570e66db0086cfb5e08a0cc8253abfd9.png)
> 
> Politoscope project: [https://politoscope.org/2019/03/gdn-preliminaires/](https://politoscope.org/2019/03/gdn-preliminaires/)
> 
> æœ€ç»ˆï¼Œæˆ‘èƒ½å¤Ÿå°†æˆ‘çš„ Spark NLP ç®¡é“æ”¾åœ¨ä¸€ä¸ªé›†ç¾¤ä¸­ï¼Œè¯¥é›†ç¾¤æ‹¥æœ‰è¶…è¿‡ 25 ä¸‡ç”¨æˆ·ç”Ÿæˆçš„æ•°ç™¾ä¸‡ä¸ªå¥å­ã€‚å½“ä½ è¢«å›°åœ¨ä¸€å°æœºå™¨ä¸Šæ—¶ï¼Œè¿™äº›ç±»å‹çš„ NLP é¡¹ç›®æ˜¯éå¸¸å›°éš¾çš„ï¼Œç”šè‡³å‡ ä¹æ˜¯ä¸å¯èƒ½çš„ã€‚
> 
> **å›åˆ°æˆ‘ä»¬è‡ªå·±çš„æ¼”ç¤º**ï¼åœ¨é›†ç¾¤ä¸­ï¼Œæˆ‘ä»¬éœ€è¦åšçš„å°±æ˜¯å°†æ•°æ®å¸§ä» 1 ä¸ªåˆ†åŒº(å› ä¸ºå®ƒæ˜¯ 1 ä¸ªæ–‡ä»¶)é‡æ–°åˆ†åŒºåˆ°å¤§çº¦ 60 ä¸ªåˆ†åŒº(å–å†³äºæœ‰å¤šå°‘ä¸ªæ‰§è¡Œå™¨ï¼Œæ¯ä¸ªæ‰§è¡Œå™¨æœ‰å¤šå°‘ä¸ªå†…æ ¸ï¼Œç­‰ç­‰ã€‚).è¿™æ ·ï¼ŒSpark å¯ä»¥å°†ä»»åŠ¡åˆ†é…ç»™æ›´å¤šçš„æ‰§è¡Œè€…ï¼Œå¹¶å¹¶è¡Œè¿è¡Œå®ƒä»¬:
> 
> ```
> **muellerFirstVol**.rdd.getNumPartitions
> val newMuellerFirstVolDF = **muellerFirstVol**.repartition(60)//Now this runs in parallelval nlpPipelineModel = pipeline.**fit**(**newMuellerFirstVolDF**)
> val nlpPipelinePrediction = nlpPipelineModel.**transform**(**newMuellerFirstVolDF**)
> ```
> 
> **æ³¨æ„**:æˆ‘åˆ›å»ºæ–°æ•°æ®å¸§çš„åŸå› æ˜¯ï¼Œrdd æœ¬è´¨ä¸Šæ˜¯ä¸å¯å˜çš„ã€‚æ‰€ä»¥ä½ ä¸èƒ½åªæ”¹å˜ä»–ä»¬çš„åˆ†åŒºæ•°é‡ã€‚ä½†æ˜¯ï¼Œæ‚¨å¯ä»¥åˆ›å»ºå…·æœ‰ä¸åŒæ•°é‡åˆ†åŒºçš„æ–° rdd(æ•°æ®å¸§)ã€‚
> 
> è¿™ä¸€æ¬¡ï¼Œåœ¨é›†ç¾¤ä¸Šè¿è¡Œç®¡é“ç”¨äº† **0.4 ç§’ï¼Œè€Œä¸æ˜¯ 3 ç§’**ã€‚ä¹Ÿè®¸åœ¨ä¸€ä¸ªä½œä¸šä¸­å¿«å‡ ç§’é’Ÿå¹¶ä¸å€¼å¾—æ³¨æ„ï¼Œä½†æ˜¯æ‚¨å¯ä»¥å°†å®ƒåº”ç”¨äºæ•°ä¸‡ä¸ª pdf æˆ–æ•°ç™¾ä¸‡æ¡è®°å½•ï¼Œè¿™æ ·æˆ‘ä»¬å°±å¯ä»¥åˆ©ç”¨ Apache Spark åˆ†å¸ƒå¼å¼•æ“ã€‚
> 
> ![](img/ca087f076c3c5215be369947fd483e33.png)
> 
> Apache Spark on a cluster
> 
> ç°åœ¨è®©æˆ‘ä»¬æ¥çœ‹çœ‹æˆ‘ä»¬å®šåˆ¶çš„ç®¡é“çš„ç»“æœã€‚æˆ‘æƒ³åšçš„æ˜¯å¯¹ NER æ¨¡å‹ä¸­çš„ç»„å—è¿›è¡Œç®€å•çš„åˆ†ç»„:
> 
> ![](img/b49bfa4358c8d18fbdd1beab427c569a.png)
> 
> Spark NLP: NER chunking on Mueller Report
> 
> æ­£å¦‚ä½ æ‰€çœ‹åˆ°çš„ï¼Œå®ƒéœ€è¦ä¸€äº›æ•°æ®æ¸…ç†ï¼Œä»¥æ’é™¤é”™è¯¯çš„å®ä½“ï¼Œå¦‚â€œpâ€ã€‚æˆ‘ä»¬å°†åœ¨ç¬¬äºŒéƒ¨åˆ†ã€‚å¦‚æœæˆ‘ä»¬åœ¨ Mueller æŠ¥å‘Šçš„ç¬¬ä¸€å·ä¸­åˆ›å»ºè¿™äº›å‘½åå®ä½“çš„å…±ç°çŸ©é˜µï¼Œæˆ‘ä»¬å¯ä»¥åœ¨ Gephi ä¸­å¯è§†åŒ–å®ƒä»¬ï¼Œæˆ‘å°†åœ¨ç¬¬ä¸‰éƒ¨åˆ†è§£é‡Šå¦‚ä½•å®ç°:
> 
> ![](img/49b750e814950d53c69f942683643d21.png)![](img/4cdf964aadcb81184927f0ff397a6f82.png)![](img/c4741a67658ce452cab52e701661d127.png)![](img/6888931369cd4499328d47ddd704d642.png)
> 
> Spark NLP: Mueller Report Named Entities co-occurrence graph
> 
> # æ¥ä¸‹æ¥æ˜¯ä»€ä¹ˆ:
> 
> æ­å–œä½ ï¼ç°åœ¨ï¼Œæ‚¨å·²ç»çŸ¥é“å¦‚ä½•ä½¿ç”¨ Spark NLP é¢„è®­ç»ƒç®¡é“å’Œæ¨¡å‹åœ¨ Apache Spark ä¸­æ‰§è¡Œ NLP ä»»åŠ¡ã€‚è¿™ä¸ºæ‚¨æä¾›äº† Apache Spark ä¸­åˆ†å¸ƒå¼å¼•æ“çš„ä¼˜åŠ¿ï¼Œå¯ä»¥åœ¨æ•°åƒä¸ª CPU å†…æ ¸ä¸Šè¿è¡Œå¤§è§„æ¨¡ NLP ä½œä¸šã€‚
> 
> è¯·è®°ä½ï¼Œè¿™æ˜¯å¼€å§‹ä½¿ç”¨ Spark NLP çš„ä¸€ç§éå¸¸å¿«é€Ÿç®€å•çš„æ–¹æ³•ã€‚åœ¨ä¸‹ä¸€éƒ¨åˆ†ä¸­ï¼Œæˆ‘æƒ³è¯•éªŒä¸€ä¸ªç”± BERT å•è¯åµŒå…¥è€Œä¸æ˜¯ GloVe è®­ç»ƒçš„ NER æ¨¡å‹ï¼Œåœ¨ Spark NLP ä¸­ä»é€šç”¨ä¾å­˜å…³ç³»è®­ç»ƒæˆ‘è‡ªå·±çš„ POS æ ‡è®°å™¨æ¨¡å‹ï¼Œè¿è¡Œä¸€äº›æ•°æ®æ¸…æ´—ï¼Œæœ€åé€šè¿‡ POS å’Œ NER åˆ†å—æå–ä¸€äº›å…³é”®å­—/çŸ­è¯­ã€‚
> 
> # èµ„æº:
> 
> *   [*GitHub ä¸Šçš„ Spark NLP*](https://github.com/JohnSnowLabs/spark-nlp)
> *   [*Spark NLP ç½‘ç«™*](https://nlp.johnsnowlabs.com/)
> *   [*Spark NLP ç¤ºä¾‹*](https://github.com/JohnSnowLabs/spark-nlp-workshop)
> *   [ç«èŠ± NLP ç®¡é“](https://nlp.johnsnowlabs.com/docs/en/pipelines)
> *   [Spark NLP è½¦å‹](https://nlp.johnsnowlabs.com/docs/en/models)
> *   [*ç«èŠ± NLP æ¾å¼›*](https://join.slack.com/t/spark-nlp/shared_invite/enQtNjA4MTE2MDI1MDkxLWVjNWUzOGNlODg1Y2FkNGEzNDQ1NDJjMjc3Y2FkOGFmN2Q3ODIyZGVhMzU0NGM3NzRjNDkyZjZlZTQ0YzY1N2I)
> *   [*Spark NLP vs å…¶ä»– NLP åº“*](https://blog.dominodatalab.com/comparing-the-functionality-of-open-source-natural-language-processing-libraries/)
> *   [*ç«èŠ± NLP vs ç©ºé—´*](https://www.oreilly.com/ideas/comparing-production-grade-nlp-libraries-training-spark-nlp-and-spacy-pipelines)
> *   [*tensor flow ä¾›ç”µçš„ Spark NLP*](/@saif1988/spark-nlp-walkthrough-powered-by-tensorflow-9965538663fd)
> 
> # é—®é¢˜ï¼Ÿ
> 
> å¦‚æœæ‚¨æœ‰ä»»ä½•é—®é¢˜ï¼Œè¯·åœ¨è¿™é‡Œç•™è¨€æˆ–åœ¨ [Twitter](https://twitter.com/MaziyarPanahi) ä¸Šå‘æ¨æ–‡ç»™æˆ‘ã€‚
> 
> è§‰å¾—è¿™ç¯‡æ–‡ç« æœ‰è¶£ï¼Ÿè¯·åœ¨åª’ä½“ä¸Šå…³æ³¨æˆ‘( [Maziyar Panahi](https://medium.com/u/fe4b780b61e1?source=post_page-----32490a8f8f12--------------------------------) )ä»¥è·å–æœªæ¥çš„æ–‡ç« å’ŒæŒå£°ğŸ‘å¦‚æœä½ å–œæ¬¢çš„è¯ï¼Œæ¥å‡ æ¬¡å§ï¼ğŸ˜Š